{"componentChunkName":"component---src-templates-blog-post-js","path":"/AI/DL/stable-diffusion-pipe/","result":{"data":{"allMarkdownRemark":{"totalCount":53},"markdownRemark":{"id":"85756ac4-947a-5dc4-a005-a9c53b94d8fd","html":"<p>Hugging Face의 <a href=\"https://huggingface.co/CompVis/stable-diffusion-v1-4\"><code>CompVis/stable-diffusion-v1-4</code></a>(Click!) 모델 API를 이용하여 프롬프트에 대한 이미지를 생성해보았다.</p>\n<br>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">import</span><span class=\"mtk1\"> torch</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">from</span><span class=\"mtk1\"> diffusers </span><span class=\"mtk7\">import</span><span class=\"mtk1\"> StableDiffusionPipeline</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">token </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> </span><span class=\"mtk4\">...</span><span class=\"mtk1\"> </span><span class=\"mtk3\"># huggingface-cli token</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">pipe </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> StableDiffusionPipeline.from_pretrained(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk11\">&quot;CompVis/stable-diffusion-v1-4&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk19 mtki\">revision</span><span class=\"mtk7\">=</span><span class=\"mtk11\">&quot;fp16&quot;</span><span class=\"mtk1\">,             </span><span class=\"mtk3\"># fp16 branch를 가져온다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk19 mtki\">torch_dtype</span><span class=\"mtk7\">=</span><span class=\"mtk1\">torch.float16,   </span><span class=\"mtk3\"># torch.float16 타입의 텐서를 가져온다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk19 mtki\">use_auth_token</span><span class=\"mtk7\">=</span><span class=\"mtk1\">token,        </span><span class=\"mtk3\"># 외부에서 API를 활용하기 위해 token을 전달한다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">pipe </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> pipe.to(</span><span class=\"mtk11\">&quot;cuda&quot;</span><span class=\"mtk1\">)</span></span></span></code></pre>\n<p>특히, <strong>Apple Silicon(arm64, M1)</strong> 환경에서 위 코드를 실행하며 마주쳤던 에러와 한계점에 대해 기록하고자 한다.</p>\n<ul>\n<li>macOS Monterey 12.5.1</li>\n<li>Apple M1</li>\n<li>Python 3.10.10</li>\n</ul>\n<p>위의 코드는 float32 대신 float16 타입으로 모델을 로딩하도록 하며, 로딩한 파이프라인을 CUDA를 사용해 연산하고자 한다. 그러나 CUDA는 NVIDIA GPU에서 동작하는 프로그램으로, M1에서는 동작하지 않는다.</p>\n<br>\n<h3>먼저 <code>diffusers==0.8.0</code> 버전이 필요하다.</h3>\n<p>먼저, <code>diffusers</code> 라이브러리의 버전 제약이 있었다. 이는 <code>CompVis/stable-diffusion-v1-4</code> 모델의 문제로 생각되는데, <code>0.8.0</code> 이하의 버전에서는 TypeError: AttributeError를 마주했다. <a href=\"https://huggingface.co/CompVis/stable-diffusion-v1-4/discussions/158\">해결 방법</a>은 단순하게 모델 버전을 업데이트해주는 것이다. <code>requirements.txt</code> 등으로 의존성을 관리한다면 <code>diffusers==0.8.0</code>를 입력하는 것으로 해결할 수 있다.</p>\n<br>\n<h3>[arm] PyTorch에서 MPS device를 사용해 GPU를 활용할 수 있다.</h3>\n<p>MPS device는 arm에서 동작하는 GPU 활용 프로그램이다. M1(Apple Silicon)이 arm64 구조이므로 MPS 설정을 통해 GPU를 활용할 수 있다.</p>\n<p><a href=\"https://discuss.pytorch.kr/t/apple-m1-m2-gpu/286\">PyTorch 사용자 모임</a>에서 안내하는 방법으로 MPS device를 활용할 수 있다.</p>\n<ol>\n<li>우선 <code>pip</code>로 다음 라이브러리를 설치한다.</li>\n</ol>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk8\">!</span><span class=\"mtk1\">pip3 install </span><span class=\"mtk8\">--</span><span class=\"mtk1\">pre torch torchvision torchaudio </span><span class=\"mtk8\">--</span><span class=\"mtk1\">extra</span><span class=\"mtk7\">-</span><span class=\"mtk1\">index</span><span class=\"mtk7\">-</span><span class=\"mtk1\">url https:</span><span class=\"mtk7\">//</span><span class=\"mtk1\">download.pytorch.org</span><span class=\"mtk7\">/</span><span class=\"mtk1\">whl</span><span class=\"mtk7\">/</span><span class=\"mtk1\">nightly</span><span class=\"mtk7\">/</span><span class=\"mtk1\">cpu</span></span></span></code></pre>\n<ol start=\"2\">\n<li>torch의 버전과 빌드 상태를 확인한다.</li>\n</ol>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"2\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">import</span><span class=\"mtk1\"> torch</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15\">print</span><span class=\"mtk1\">(torch.__version__)                 </span><span class=\"mtk3\"># torch 1.12 이상에서 MPS 장치를 지원한다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15\">print</span><span class=\"mtk1\">(torch.backends.mps.is_built())     </span><span class=\"mtk3\"># MPS 장치를 지원하도록 빌드되었는지 확인한다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15\">print</span><span class=\"mtk1\">(torch.backends.mps.is_available()) </span><span class=\"mtk3\"># MPS 장치가 사용가능한지 확인한다.</span></span></span></code></pre>\n<ol start=\"3\">\n<li><code>\"cuda\"</code> 대신 <code>\"mps\"</code> 키워드로 활용할 수 있다.</li>\n</ol>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"3\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">device </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> torch.device(</span><span class=\"mtk11\">&quot;mps&quot;</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">x </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> torch.ones(</span><span class=\"mtk4\">10</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">device</span><span class=\"mtk7\">=</span><span class=\"mtk1\">device)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">model </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> MyModel()</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">model.to(</span><span class=\"mtk11\">&quot;mps&quot;</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">model.pred(x)</span></span></span></code></pre>\n<br>\n<h3>MPS device로 <code>fp16</code> 활용하기?</h3>\n<p>는 아직 공식적으로 불가능하다. 글을 작성하는 시점의 <a href=\"https://huggingface.co/CompVis/stable-diffusion-v1-4/discussions/13\">모델 Discussion</a>에 따르면 Hugging Face 팀에서 이슈에 대해 작업하고 있다고 하나 아직 공식적인 해결 방법은 없는 듯 하다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"4\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">pipe </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> StableDiffusionPipeline.from_pretrained(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk11\">&quot;CompVis/stable-diffusion-v1-4&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk19 mtki\">revision</span><span class=\"mtk7\">=</span><span class=\"mtk11\">&quot;fp16&quot;</span><span class=\"mtk1\">,                </span><span class=\"mtk3\"># fp16 branch를 가져온다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk19 mtki\">torch_dtype</span><span class=\"mtk7\">=</span><span class=\"mtk1\">torch.float16,      </span><span class=\"mtk3\"># torch.float16 타입의 텐서를 가져온다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk19 mtki\">use_auth_token</span><span class=\"mtk7\">=</span><span class=\"mtk1\">token,           </span><span class=\"mtk3\"># 외부에서 API를 활용하기 위해 token을 전달한다.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">).to(</span><span class=\"mtk11\">&quot;mps&quot;</span><span class=\"mtk1\">)</span></span></span></code></pre>\n<p>MPS device에 파이프라인을 탑재하는 것은 문제가 없으나, inference를 얻고자 하면 1. 커널이 종료되거나, 2. <code>RuntimeError: \"upsample_nearest2d_channels_last\" not implemented for 'Half’</code>를 마주하거나, 3. <code>RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'</code>를 마주하는 현상이 나타난다. (바로 아래 코드를 실행하는 데에 있어 주피터 노트북의 활성 상태에 따라 다른 에러가 나타났다.)</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"5\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">prompt </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> </span><span class=\"mtk11\">&quot;...&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">image </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> pipe(prompt).images[</span><span class=\"mtk4\">0</span><span class=\"mtk1\">]</span></span></span></code></pre>\n<p>즉 위의 코드는 현재로서 에러 없이 구현이 불가능하다. <em>(2023.06.07)</em></p>\n<p>현재로서 파이프라인을 활용하기 위해서는 아래와 같이 fp16 옵션 없이 cpu에 파이프라인을 로드해야 한다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"6\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">pipe </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> StableDiffusionPipeline.from_pretrained(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk11\">&quot;CompVis/stable-diffusion-v1-4&quot;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># revision=&quot;fp16&quot;,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># torch_dtype=torch.float16,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk19 mtki\">use_auth_token</span><span class=\"mtk7\">=</span><span class=\"mtk1\">token,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">)</span></span></span></code></pre>\n<p>위 코드로 가상환경에서 파이프라인을 로드했을 때 <em>14분</em> 가량의 시간이 소요되었는데, Colab의 T4 GPU 환경에서 CUDA를 활용했을 때 _47초_가 걸린것에 비하면 매우 느린 속도이다. 또한 매번 inference를 구할 때의 연산량도 많으므로, 현재로서는 M1 디바이스를 제대로 활용하기 어렵다고 보인다.</p>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .abyss { background-color: #000c18; }\n  .abyss .mtki { font-style: italic; }\n  .abyss .mtk7 { color: #225588; }\n  .abyss .mtk1 { color: #6688CC; }\n  .abyss .mtk4 { color: #F280D0; }\n  .abyss .mtk3 { color: #384887; }\n  .abyss .mtk11 { color: #22AA44; }\n  .abyss .mtk19 { color: #2277FF; }\n  .abyss .mtk8 { color: #F8F8F0; }\n  .abyss .mtk15 { color: #9966B8; }\n  .abyss .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));\n  }\n</style>","frontmatter":{"title":"[DL] Apple M1에서 HuggingFace API 활용하기","date":"June 07, 2023"}}},"pageContext":{"slug":"/AI/DL/stable-diffusion-pipe/","previous":{"fields":{"slug":"/AI/DL/vscode-setting/"},"frontmatter":{"title":"[DL] Apple M1에서 VS code 환경 세팅하기"}},"next":{"fields":{"slug":"/AI/DL/optimization-1/"},"frontmatter":{"title":"[DL] Gradient Descent와 문제들"}}}},"staticQueryHashes":["1185972000","3231742164"],"slicesMap":{}}