{"componentChunkName":"component---src-templates-blog-post-js","path":"/AI/NLP/transformer/","result":{"data":{"allMarkdownRemark":{"totalCount":29},"markdownRemark":{"id":"0db6b306-7fbb-5e1e-abb2-13d941036ef4","html":"<blockquote>\n<p>Paper : Vaswani et al., 2017, \"Attention is all you need\" (<a href=\"https://arxiv.org/abs/1706.03762\">Link to arxiv</a>)</p>\n</blockquote>\n<br>\n<br>\n<h2>0. Transformer</h2>\n<p>트랜스포머는 RNN Seq2Seq 모델과 비슷한 인코더-디코더 구조를 갖고 있지만, 보다 긴 시퀀스를 효율적으로 다룰수 있는 모델로 환영받았다. 트랜스포머는 새로운 어텐션을 도입했다. 2014년에 등장한 어텐션(Bahdanau et al., 2014)이 RNN 네트워크의 성능을 향상시키는 활용된 것과 달리, 2017년의 어텐션은 신경망을 이용하지 않고 행렬 곱으로 이루어진 방식을 제안하면서 자연어 처리에 있어 획기적인 성능 향상을 불러왔다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 71.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAABjUlEQVR42qWTYW/SUBSG+f+f1Q9+NCbqYtTAFueEABNLC7bYUcpGBjIJha4VaCkFWtrHtEajyYZU3+Tmntz73ifnJufNxXHM31ai1WqFbdkQs9ebOwSW7FpPoyJVmbvzX2f/DNztdkjSJ45P3mEY0/8H+r5P4fQNr05eIDbqLN3lvdDcfZAfDyCOwHFc8nWFI1FFVDvMbPtwYKIwDLnqXSI2SpTKBTqdNpX3R7x9/QjhQxEnS4eJ1r6PJLd4ft7gWVlA+ayiVPNcVF+iq02MiZkN6HkeHV2nJgkITZHhcEixlKdw/BRRrLFYOBmBK5+WLNE4e0wl/5Drno5SfIJ29gBdPsey5xm/vN7QvlBpCSXkWpGJMUZtfkSqntJWFRaOm/qiKNoP/GkyTZN+f4DWvWJkTNhFEda3GVr3ksGXYXofBMGdXd4J3Gy3zCyLrlDnWlZYex5fdR21XGY6GuEul4cB/xidIGB6c8N4MEhryzAY9/tsfP+3Oc2QlESbYEsQhmntuA7m7W0aw33R+w4wBTBcVQiMxgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"transformer structure\"\n        title=\"\"\n        src=\"/static/d251194d238dd0e07ab438d0dc0f629c/c1b63/transformer-structure.png\"\n        srcset=\"/static/d251194d238dd0e07ab438d0dc0f629c/5a46d/transformer-structure.png 300w,\n/static/d251194d238dd0e07ab438d0dc0f629c/0a47e/transformer-structure.png 600w,\n/static/d251194d238dd0e07ab438d0dc0f629c/c1b63/transformer-structure.png 1200w,\n/static/d251194d238dd0e07ab438d0dc0f629c/54c3a/transformer-structure.png 1257w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\nThe structure of transformer, Vaswani et al., 2017</p>\n<p>트랜스포머 모델은 크게 봐서 왼쪽의 인코더와 오른쪽의 디코더를 가지는 구조이다. RNN 모델에서와 마찬가지로 인코더의 결과값을 디코더의 입력값과 결합해서 연산을 거쳐 결과값을 도출한다. 다만 RNN과의 차이점은 시퀀스를 <strong>동시에</strong> 처리한다는 점이다. 즉 시퀀스 모델처럼 시퀀스 데이터에 순서대로 접근해서 하나씩 처리하는 것이 아니라 전체 시퀀스를 한 번에 연산한다. 따라서 분산 연산이 용이하며 RNN 모델에서 발생하는 vanishing gradient 현상에 효과적으로 대처해서 보다 긴 시퀀스를 다룰 수 있게 되었다.</p>\n<p>트랜스포머 네트워크에 사용되는 어텐션은 행렬곱을 이용한 순차적이지 않은 (따라서 병렬 연산이 가능한) 어텐션이며, 이 어텐션을 Scaled-Dot product 어텐션이라고 한다.</p>\n<br>\n<h3>🔔 Scaled-Dot prooduct Attention</h3>\n<p>Scaled-Dot prooduct 어텐션에는 세개의 행렬 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span> 입력이 필요하다:</p>\n<ul>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, Queries : 비교하고자 하는 시퀀스로, 키 K와 유사도를 측정한다.</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, Keys : 비교 대상이 되는 시퀀스로, 쿼리 Q와 유사도를 측정한다.</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>, Values : <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">QK</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>의 가중치가 곱해지는 행렬이다.</li>\n</ul>\n<p>어텐션이란 행렬 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>와 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>-<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span> 쌍을 결과값에 매핑하는 함수로, 결과값은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>의 가중치 합으로 계산되고, 각각의 값 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span>에 할당된 가중치는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span>와 그에 대응하는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>로부터 계산된다. 이 어텐션이 이름 붙은 이유는 어텐션을 연산하는 방법에 있다.</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>Q</mi><mo>⋅</mo><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy=\"false\">)</mo><mo>⋅</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">Attention(Q, K, V) = softmax(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}) \\cdot V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">tt</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.4483em;vertical-align:-0.93em;\"></span><span class=\"mord mathnormal\">so</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5183em;\"><span style=\"top:-2.2528em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8572em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8172em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1828em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></div>\n<p>첫 번째 행렬 곱(dot product)은 쿼리 Q와 키 K의 유사도를 분석하고, 두번째 곱은 softmax 함수값으로 얻어진 가중치를 발류 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>에 할당한다. <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>와 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>의 곱은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>의 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>의 루트로 조정(scaled) 하는데, 이 스케일링은 reguralization효과를 가진다. 그 다음 softmax 함수를 거쳐 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>와 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>의 유사도를 가중치로 변환해 마지막으로 그 값을 행렬 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>에 반영해 모든 쿼리의 어텐션을 얻을 수 있다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1104px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 61.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAABrUlEQVR42o2Tz0oCURTGB3GwxJVWq3DRQnJh/xx1Ey4MXaggBK4MLCRFwlE0dz2ES5/CJ+gBpH2rghaN0YiSKMnM6PjFPTGhw1gdOJy5d8734ztz73CLxQLmZDGdTjGZTKCqKvr9PnR9Dk3TKGezGVUWyxoWHJZi+aUBY/H88oThpwxNm2E8GdMeg5phBLRyqCgKOp0OxKqIUqmEq8Il8tcXqNfrKJfLKBaLaLfbBNB1fdWhGcYaepKEXC6HaDQKjuMsMx6PrzhdARrjAt/P8uADB4dH8Hq9EMIh7O/uIXFySqDNjQ2qmUyGeufzubVDFqqi4LX3hvuHRwSOQyTc2tnG3c0tzoUzWvN2nmoymfwHUFUhy+8YDAaIRCIkZGOzdLvd8Hg8sNlstJ9KpdYDzSc8HA4RDAZJaLfbqSYSCeTz+Z9vuBZodWUkSYIgCCQ0HDmdThQKBQQCAVqn0+nfR14GyrKMcDhMQofDAZ7nCcxqs9mE3+9HLBZbf8rmZCMbTszpcrng8/mQzWb/dmg0jEYjtFotutSiKKJSqaBaraLRaKBWq9Fet9u1/PW+AEDQ3IOynqY9AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"transformer attention\"\n        title=\"\"\n        src=\"/static/8c829fba5d92c05239fe7a3d488cda81/7388e/transformer-attention.png\"\n        srcset=\"/static/8c829fba5d92c05239fe7a3d488cda81/5a46d/transformer-attention.png 300w,\n/static/8c829fba5d92c05239fe7a3d488cda81/0a47e/transformer-attention.png 600w,\n/static/8c829fba5d92c05239fe7a3d488cda81/7388e/transformer-attention.png 1104w\"\n        sizes=\"(max-width: 1104px) 100vw, 1104px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Attention, Badnau et al., 2015</p>\n<p>어텐션은 쿼리와 키의 heatmap을 생성하는 것과 같다. 전체 시퀀스를 한 번에 단어 쌍 단위 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(q, k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose\">)</span></span></span></span></span>로 살펴보기 때문에, 단어가 문장에서 등장하는 순서에 관계없이 유사도를 계산할 수 있다. 위의 예처럼 어순이 다른 영어와 프랑스어 문장에서도 단어의 대응 관계를 제대로 파악할 수 있다.</p>\n<br>\n<h3>🔔 Multi-Head Attention</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 834px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 36.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABWklEQVR42l1RXUvDQBDM/38RfBcEnwUpKD5YX2qpShLaQmtN0jafTUtaTNNcIvno6CxUxYNl75bZmdk9Lc9zBEGA7LCHKgpMJhOMRiOYponxeCyh6zrW6zXiOIbt2HBsR/C98QNuB9cIExc8x+MRmlIKURRJg+/7cBwHrutiNptJDAYDDIdD9Pt92LaN/JCj/CxRtQ2CKILre0izPU5HK4pClDebDVar1Y8Tz/MQhqHkJEmw2+1QVZU0faoC5n0PL50unjtdvHYeES8CtHTIkensr0vm5XIpAlzHdrtFWZbI9pkQpnGCp4sbdM4ucXd+JXfvzUFeqF9CNpOUI/NtWRYWi4XskDXulG7ruhbnFGR9Op0KnsKcQqMyyRgc9QRmZgP3R2LDMMQ5DbD2blmCoyDJDF3HfD6Hxp9p2xZN00img1Ow9j+I/0hTNHUDVSqkWSpr2B8Ujt+f8gVBAwKJwx0R6gAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"transformer multi head attention\"\n        title=\"\"\n        src=\"/static/30264da045e993647985458dc2263503/5d72a/transformer-multi-head-attention.png\"\n        srcset=\"/static/30264da045e993647985458dc2263503/5a46d/transformer-multi-head-attention.png 300w,\n/static/30264da045e993647985458dc2263503/0a47e/transformer-multi-head-attention.png 600w,\n/static/30264da045e993647985458dc2263503/5d72a/transformer-multi-head-attention.png 834w\"\n        sizes=\"(max-width: 834px) 100vw, 834px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Multi-Head Attention, from deeplearning.ai</p>\n<p>트랜스포머의 어텐션의 또다른 특징은 어텐션이 머리(heads)를 여러개 가진다는 것이다. 입력값에 대해 어텐션을 여러번 수행한 후 결과를 결합(concatenate)해서 최종적으로 하나의 행렬을 만드는 것을 뜻한다. <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 차원의 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>에 대해 일회 어텐션을 적용하는 대신 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>를 <code>n_heads</code>번 선형 투사(linear projection)해서 서로다른 학습된 선형 투사들에 대해 어텐션을 적용한다. 각 선형 투사를 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>에 대해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>에 대해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>에 대해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></span></span></span></span></span></span></span>라고 하며 각각 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n_{seq}, d_k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">se</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n_{seq}, d_k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">se</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>v</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n_{seq}, d_v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">se</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 차원을 가진다. 어텐션을 적용하면 한개의 결과값에 대해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>v</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n_{seq}, d_v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">se</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 차원을 가지므로 <code>n_heads</code>개의 결과값을 결합한 행렬 다시 선형 투사해서 어텐션 결과값을 얻는다. 매번 학습할 때마다 다른 가중치를 가지므로 여러번 어텐션을 적용함으로서 시퀀스 데이터 사이의 다양한 관계를 학습할 수 있다. 이때 여러번의 어텐션을 순서대로 실행해야 할 필요가 없으므로 병렬 연산을 하기 용이한 구조다.</p>\n<br>\n<p>📂 다음 코드는 Trax <code>SplitIntoHeads</code>와 <code>MergeHeads</code> 메서드로, Multi-Head 어텐션의 일부분을 구현한다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">SplitIntoHeads</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">merged_batch_and_head</span><span class=\"mtk7\">=</span><span class=\"mtk4\">True</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk11\">&quot;&quot;&quot;Returns a layer that reshapes an array for multi-head computation.&quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">f</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">x</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    batch_size, seq_len, d_feature </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.shape</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> d_feature </span><span class=\"mtk7\">%</span><span class=\"mtk1\"> n_heads </span><span class=\"mtk7\">!=</span><span class=\"mtk1\"> </span><span class=\"mtk4\">0</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk7\">raise</span><span class=\"mtk1\"> </span><span class=\"mtk15 mtki\">ValueError</span><span class=\"mtk1\">(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          </span><span class=\"mtk15 mtki\">f</span><span class=\"mtk11\">&#39;Feature embedding dimensionality (</span><span class=\"mtk4\">{</span><span class=\"mtk1\">d_feature</span><span class=\"mtk4\">}</span><span class=\"mtk11\">) is not a multiple&#39;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          </span><span class=\"mtk15 mtki\">f</span><span class=\"mtk11\">&#39; of the requested number of attention heads (</span><span class=\"mtk4\">{</span><span class=\"mtk1\">n_heads</span><span class=\"mtk4\">}</span><span class=\"mtk11\">).&#39;</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    d_head </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> d_feature </span><span class=\"mtk7\">//</span><span class=\"mtk1\"> n_heads</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># (b_size, seq_len, d_feature) --&gt; (b_size*n_heads, seq_len, d_head)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    x </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.reshape((batch_size, seq_len, n_heads, d_head))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    x </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.transpose((</span><span class=\"mtk4\">0</span><span class=\"mtk1\">, </span><span class=\"mtk4\">2</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk4\">3</span><span class=\"mtk1\">))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> merged_batch_and_head:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      x </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.reshape((batch_size </span><span class=\"mtk7\">*</span><span class=\"mtk1\"> n_heads, seq_len, d_head))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> x</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> Fn(</span><span class=\"mtk11\">&#39;SplitIntoHeads&#39;</span><span class=\"mtk1\">, f)</span></span></span></code></pre>\n<p><code>SplitIntoHeads</code>는 <code>d_feature</code>(그림에서는 <code>d_model</code>)가 Head의 개수 <code>n_heads</code>의 정수배일 것을 강제한다. 위의 그림처럼 <code>(batch, seq_len, d_feature)</code>을 입력받아 <code>(b_size*n_heads, seq_len, d_head)</code>차원을 출력하고 있다. 그 다음 <code>PureAttention</code>처럼 1개 Head에 대한 어텐션을 <code>n_heads</code>만큼 수행한 후, 여러 Head를 <code>MergeHeads</code>로 결합한다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">MergeHeads</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">merged_batch_and_head</span><span class=\"mtk7\">=</span><span class=\"mtk4\">True</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk11\">&quot;&quot;&quot;Returns a layer that rejoins heads, after multi-head computation.&quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">f</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">x</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> merged_batch_and_head:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      dim_0, seq_len, d_head </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.shape</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> dim_0 </span><span class=\"mtk7\">%</span><span class=\"mtk1\"> n_heads </span><span class=\"mtk7\">!=</span><span class=\"mtk1\"> </span><span class=\"mtk4\">0</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk7\">raise</span><span class=\"mtk1\"> </span><span class=\"mtk15 mtki\">ValueError</span><span class=\"mtk1\">(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk15 mtki\">f</span><span class=\"mtk11\">&quot;Array&#39;s leading dimension (</span><span class=\"mtk4\">{</span><span class=\"mtk1\">dim_0</span><span class=\"mtk4\">}</span><span class=\"mtk11\">) is not a multiple of the&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk15 mtki\">f</span><span class=\"mtk11\">&quot; number of attention heads (</span><span class=\"mtk4\">{</span><span class=\"mtk1\">n_heads</span><span class=\"mtk4\">}</span><span class=\"mtk11\">).&quot;</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      batch_size </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> dim_0 </span><span class=\"mtk7\">//</span><span class=\"mtk1\"> n_heads</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      x </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.reshape((batch_size, n_heads, seq_len, d_head))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">else</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      batch_size, _, seq_len, d_head </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.shape</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># (b_size, n_heads, seq_len, d_head) --&gt; (b_size, seq_len, d_feature)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    x </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.transpose((</span><span class=\"mtk4\">0</span><span class=\"mtk1\">, </span><span class=\"mtk4\">2</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk4\">3</span><span class=\"mtk1\">))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    x </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.reshape((batch_size, seq_len, n_heads </span><span class=\"mtk7\">*</span><span class=\"mtk1\"> d_head))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> x</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> Fn(</span><span class=\"mtk11\">&#39;MergeHeads&#39;</span><span class=\"mtk1\">, f)</span></span></span></code></pre>\n<p>함수 <code>f</code>는 <code>(batch_size, n_heads, seq_len, d_head)</code> 차원의 입력값을 어텐션 블럭의 입력값 차원 <code>(b_size, seq_len, d_feature)</code>로 변형해서 반환한다.</p>\n<br>\n<br>\n<h2>1. Encoder</h2>\n<p>널리 쓰이는 트랜스포머 사전훈련 모델인 BERT의 경우 인코더만 (<code>bert-large</code>의  경우) 24개 쌓은 네트워크다. LSTM을 생각해 보면 인코더의 구조는 상대적으로 단순해 보이지만, 인코더만으로도 많은 작업을 수행할 수 있음을 알 수 있다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAABsklEQVR42p2STWvbQBCG9f//QW+99NJDaAtpobdCiA9OIW1xHVlIsiRLu9H3p6WVHb3hnRQTcuzAsMzszjNfa/V9jyiKEEYREqWg9SPyPEcYhgiCAJR5nsF30zThtdAehgHjOF58Fh8XRQHfc+HYf/H7/id834NSClmWYRyPKMtS4HEc43g8wpgJ4zQiTVNJnCSJgI0xsEgd+g5+nOHLj3t8u93AdgOcZiMZszxDFEbY7/eSmPCu6+Q8HA7wfV86ot00zQuwa2sEaYtPKxfX6z2cQKPvGmm1qio4jgPXdQVY17W0z5Mg3m23W2itJZF1Pp8RJxpp8ICbq3dYf30P5T/gaeHsjAA9z5MgBrNNtkd/27bY7XbYbDbiFyArbPsBtfJg31zBXX3GY+hg+bcMBtq2LVDO8DVQyRK1+FgxE1js3fNcJEpDpQWKusM4mct2ec/Bc4acGdsmkADarJC/hGCZIedR1hWaKMXqwzXuPn6HKTsBcmt5kUs1VMKpjKFNOKtmQuplKZTTMOHP7R226194MvOL73SSR2+VX6duKqmSc6OyXSaylmXBwg28EfH/hz4DDLrx9jbZoXYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"transformer encoder\"\n        title=\"\"\n        src=\"/static/98e8833c17d9e0c060a447cf25081023/c1b63/transformer-encoder.png\"\n        srcset=\"/static/98e8833c17d9e0c060a447cf25081023/5a46d/transformer-encoder.png 300w,\n/static/98e8833c17d9e0c060a447cf25081023/0a47e/transformer-encoder.png 600w,\n/static/98e8833c17d9e0c060a447cf25081023/c1b63/transformer-encoder.png 1200w,\n/static/98e8833c17d9e0c060a447cf25081023/ce0a7/transformer-encoder.png 1590w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Encoder structure, from deeplearning.ai</p>\n<p>인코더는 크게 <strong>두개의 레이어</strong>로 구성된다. Multi-Head Attention과 FeedForward이다. FeedForward는 일련의 훈련 가능한 신경망으로 구성된 블럭이다. 0️⃣ 입력값을 Embedding하고 Positional Encoding을 적용한 후에, 한 개의 <strong>인코더 블럭</strong>은 1️⃣ Residual을 적용한 Multi-Head Attention을 실행하고 2️⃣ 다시 Residual을 적용한 FeedForward 레이어를 실행한다. 모델을 깊게 만들기 위해 이 인코더 블럭을 여러번 실행한다.</p>\n<p>Residual 레이어는 함수 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mi>n</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Fn(x_1, x_2, ...)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">...</span><span class=\"mclose\">)</span></span></span></span></span>에 대해 다음을 뜻한다.</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>R</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>d</mi><mi>u</mi><mi>a</mi><mi>l</mi><mo stretchy=\"false\">(</mo><mi>F</mi><mi>n</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>F</mi><mi>n</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo stretchy=\"false\">)</mo><mo>+</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">Residual(Fn)(x_1, x_2, ...) = Fn(x_1, x_2, ...) + x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">es</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">...</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">...</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></div>\n<p>즉 입력값의 첫번째 값을 함수의 결과값에 더하는 기능을 한다. Residual 레이어를 적용하는 이유는 shortcut 연결 기능을 하기 때문이다. 특히 깊은 네트워크를 학습할 때 Residual이 효과적임이 검증되었다.</p>\n<blockquote>\n<p>Further study - Residual 네트워크를 사용하는 이유 : <a href=\"https://arxiv.org/pdf/1512.03385.pdf\">He et al., 2015</a></p>\n</blockquote>\n<br>\n<p>📂 다음 코드는 Trax 라이브러리의 <code>TransformerEncoder</code> 모델이다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"2\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">TransformerEncoder</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">vocab_size</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">n_classes</span><span class=\"mtk7\">=</span><span class=\"mtk4\">10</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">d_model</span><span class=\"mtk7\">=</span><span class=\"mtk4\">D_MODEL</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">d_ff</span><span class=\"mtk7\">=</span><span class=\"mtk4\">D_FF</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">n_layers</span><span class=\"mtk7\">=</span><span class=\"mtk4\">N_LAYERS</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk4\">N_HEADS</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">max_len</span><span class=\"mtk7\">=</span><span class=\"mtk4\">MAX_SEQUENCE_LENGTH</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk4\">DROPOUT_RATE</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">dropout_shared_axes</span><span class=\"mtk7\">=</span><span class=\"mtk4\">DROPOUT_SHARED_AXES</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk4\">MODE</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                       </span><span class=\"mtk19 mtki\">ff_activation</span><span class=\"mtk7\">=</span><span class=\"mtk4\">FF_ACTIVATION_TYPE</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_Dropout</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Dropout(</span><span class=\"mtk19 mtki\">rate</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout, </span><span class=\"mtk19 mtki\">shared_axes</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout_shared_axes, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_EncBlock</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> _EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         mode, ff_activation)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Serial(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Branch([], tl.PaddingMask()),  </span><span class=\"mtk3\"># Creates masks from copy of the tokens.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Embedding(vocab_size, d_model),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.PositionalEncoding(</span><span class=\"mtk19 mtki\">max_len</span><span class=\"mtk7\">=</span><span class=\"mtk1\">max_len),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      [_EncBlock() </span><span class=\"mtk7\">for</span><span class=\"mtk1\"> _ </span><span class=\"mtk7\">in</span><span class=\"mtk1\"> </span><span class=\"mtk15\">range</span><span class=\"mtk1\">(n_layers)],</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Select([</span><span class=\"mtk4\">0</span><span class=\"mtk1\">], </span><span class=\"mtk19 mtki\">n_in</span><span class=\"mtk7\">=</span><span class=\"mtk4\">2</span><span class=\"mtk1\">),  </span><span class=\"mtk3\"># Drops the masks.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Mean(</span><span class=\"mtk19 mtki\">axis</span><span class=\"mtk7\">=</span><span class=\"mtk4\">1</span><span class=\"mtk1\">),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Dense(n_classes),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  )</span></span></span></code></pre>\n<p><code>TransformerEncoder</code>는 토큰화된 텍스트를 <code>n_classes</code>개로 분류한다. 함수 반환값의 첫줄에 등장하는 <code>tl.Branch</code>는 입력값을 받아서 각각의 함수를 병렬적으로 실행한다. 즉 입력값을 리스트<code>[]</code>로 만든 값과 패딩마스크 <code>tl.PaddingMask()</code> 값 두개를 반환할 것이다. 두 값 모두 임베딩과 positional encoding을 거쳐 인코더 블럭에 입력된다. 인코더 블럭의 코드에서 데이터와 마스크 쌍 <code>(activations, mask)</code>을 입력받는 것을 확인할 수 있다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"3\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_EncoderBlock</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">d_model</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">d_ff</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">dropout_shared_axes</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">ff_activation</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk11\">&quot;&quot;&quot;Returns a list of layers that implements a Transformer encoder block.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  The input to the block is a pair (activations, mask) where the mask was</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  created from the original source tokens to prevent attending to the padding</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  part of the input. The block&#39;s outputs are the same type/shape as its inputs,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  so that multiple blocks can be chained together.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_Attention</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Attention(d_model, </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk1\">n_heads, </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> [</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Residual(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Attention(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      ),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Residual(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _FFBlock(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      ),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  ]</span></span></span></code></pre>\n<p>여기서 <code>tl.Attention</code>은 <code>n_heads</code>개의 머리를 가지는 multi-head 셀프-어텐션이며, Attention 레이어와 FeedForward 블럭이 Residual을 거치는 것을 확인할 수 있다. 어텐션 블럭을 지난 후에는 마스크가 필요 없으므로 <code>tl.Select()</code>로 <code>(activations, mask)</code>쌍에서 앞의 값만 취하고 <code>tl.LayerNorm()</code>과 같은 쿼리에 해당하는 열에 대한 덧셈 <code>tl.Mean(axis=1)</code>, 그리고 <code>n_classes</code>개의 <code>tl.Dense()</code> 층을 거쳐 마무리한다.</p>\n<br>\n<h3>🔆 Dimensionality Setting</h3>\n<p>Residual 레이어를 적용하기 위해서는 어텐션의 입력값과 결과값의 차원이 같아야한다. 앞의 Multi-Head Attention 그림을 참고하여 배치 크기를 <code>batch</code>, 입력 시퀀스 길이를 <code>length</code>, 그리고 어텐션의 차원을 <code>d_model</code>로 설정하자. Q, K, V가 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo separator=\"true\">,</mo><mi>l</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch, length, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">ba</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 차원을 가지며, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></span></span></span></span></span></span></span>는 각각 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo separator=\"true\">,</mo><mi>l</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch, length, d_k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">ba</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo separator=\"true\">,</mo><mi>l</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch, length, d_k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">ba</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo separator=\"true\">,</mo><mi>l</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>v</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch, length, d_v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">ba</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 차원이라고 하자. 위의 설정에서 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k = d_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>로 두며, 그림에서는 이 값이 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{head}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>로 나타나 있다. 어텐션을 수행하고 난 후 i번 째 어텐션은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo separator=\"true\">,</mo><mi>l</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>v</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Z_i \\in (batch, length, d_v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">ba</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">h</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 차원이 되는데, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>n</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">n_{heads}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>개의 어텐션을 결합하고 난 후 처음 입력값과 같은 차원을 얻기 위해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>n</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>s</mi></mrow></msub><mo>=</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\"> n_{heads} = d_{model} / d_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>로 설정한다. 요약하면:</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><msub><mi>d</mi><mi>v</mi></msub><mo>=</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mi mathvariant=\"normal\">/</mi><msub><mi>n</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_k = d_v = d_{model} / n_{heads}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></div>\n<br>\n<h3>🔆 Positional Encoding</h3>\n<p>인코딩에 앞서, 단순히 단어 임베딩을 통해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">QK^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0358em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span> 2차원 행렬을 계산하면 시퀀스 모델과 달리 단어의 문장 내 위치 정보를 반영할 수 없다. 그러나 어순은 맥락을 파악하는데에 중요한 단서가 된다. 예를 들어 문장 내에서 같은 단어가 등장해도 각 단어는 다른 의미를 가리킬 수 있고, 언어마다 문법 구조에 따라 어순이 다르며, 같은 단어를 사용해도 어순에 따라 다른 의미를 내포할 수 있다.</p>\n<p>따라서 위치 정보를 반영하기 위해 위치에 따른 임의의 값을 설정해 Q, K와 V의 임베딩에 <strong>더하는</strong>데, 이 것을 positional encoding이라고 한다. Trax에서는 여러가지 positional encoding 방법을 지원하고 있는데 (<a href=\"https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=positional%20encoding#module-trax.layers.research.position_encodings\">link</a>), 원 논문에서는 차원 <code>i</code>와 위치 <code>pos</code>에 대한 sine 곡선으로 표현했다.</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.25em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mi mathvariant=\"normal\">/</mi><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mi mathvariant=\"normal\">/</mi><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{aligned}\nPE_{(pos,2i)} &#x26;= sin(pos/10000^{2i/d_{model}}) \\\\\nPE_{(pos,2i+1)} &#x26;= cos(pos/10000^{2i/d_{model}})\n\\end{aligned}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:3.196em;vertical-align:-1.348em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.848em;\"><span style=\"top:-3.91em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.5198em;margin-left:-0.0576em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">os</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3552em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.312em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.5198em;margin-left:-0.0576em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">os</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3552em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.348em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.848em;\"><span style=\"top:-3.91em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">in</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">os</span><span class=\"mord\">/1000</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span><span style=\"top:-2.312em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord mathnormal\">cos</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">os</span><span class=\"mord\">/1000</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.348em;\"><span></span></span></span></span></span></span></span></span></span></span></span></div>\n<p>즉 positional encoding의 각 차원은 사인 곡선에 대응한다. PE는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mi>π</mi></mrow><annotation encoding=\"application/x-tex\">2\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span></span></span>에서 부터 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>10000</mn><mo>⋅</mo><mn>2</mn><mi>π</mi></mrow><annotation encoding=\"application/x-tex\">10000 \\cdot 2\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">10000</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span></span></span>까지의 기하학적 형태를 나타낸다. 이렇게 함으로서 상수 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>에 대해 상대적인 위치인 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo>+</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">PE(pos+k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">PE</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">os</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose\">)</span></span></span></span></span>를 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">PE(pos)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">PE</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">os</span><span class=\"mclose\">)</span></span></span></span></span>의 선형 함수로 나타낼 수 있다. trax.layers.Attention에서 정의하고 있는 <code>PositionalEncoding</code> 도 같은 방법을 적용했다.</p>\n<br>\n<p>📂 다음 코드는 Trax 라이브러리의 <code>PositionalEncoding</code> 레이어다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"4\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">class</span><span class=\"mtk1\"> </span><span class=\"mtk5 mtku\">PositionalEncoding</span><span class=\"mtk1\">(</span><span class=\"mtk6 mtki mtku\">base</span><span class=\"mtk1\">.</span><span class=\"mtk6 mtki mtku\">Layer</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">forward</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">self</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">inputs</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk11\">&quot;&quot;&quot;Returns the input activations, with added positional information.&quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    weights </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> self.weights</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    emb </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> fastmath.dynamic_slice_in_dim(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        weights, self.state, inputs.shape[</span><span class=\"mtk4\">1</span><span class=\"mtk1\">], </span><span class=\"mtk19 mtki\">axis</span><span class=\"mtk7\">=</span><span class=\"mtk4\">1</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    self.state </span><span class=\"mtk7\">+=</span><span class=\"mtk1\"> inputs.shape[</span><span class=\"mtk4\">1</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> inputs </span><span class=\"mtk7\">+</span><span class=\"mtk1\"> emb</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">init_weights_and_state</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">self</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">input_signature</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk11\">&quot;&quot;&quot;Randomly initializes the positional encoding vectors.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">    &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    d_feature </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> input_signature.shape[</span><span class=\"mtk7\">-</span><span class=\"mtk4\">1</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> self._d_feature </span><span class=\"mtk7\">is</span><span class=\"mtk1\"> </span><span class=\"mtk7\">not</span><span class=\"mtk1\"> </span><span class=\"mtk4\">None</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      d_feature </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> self._d_feature</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    pe </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> np.zeros((self._max_len, d_feature), </span><span class=\"mtk19 mtki\">dtype</span><span class=\"mtk7\">=</span><span class=\"mtk1\">np.float32)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    position </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> np.arange(</span><span class=\"mtk4\">0</span><span class=\"mtk1\">, self._max_len)[:, np.newaxis]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    div_term </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> np.exp(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        np.arange(</span><span class=\"mtk4\">0</span><span class=\"mtk1\">, d_feature, </span><span class=\"mtk4\">2</span><span class=\"mtk1\">) </span><span class=\"mtk7\">*</span><span class=\"mtk1\"> </span><span class=\"mtk7\">-</span><span class=\"mtk1\">(np.log(</span><span class=\"mtk4\">10000.0</span><span class=\"mtk1\">) </span><span class=\"mtk7\">/</span><span class=\"mtk1\"> d_feature))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    pe[:, </span><span class=\"mtk4\">0</span><span class=\"mtk1\">::</span><span class=\"mtk4\">2</span><span class=\"mtk1\">] </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> np.sin(position </span><span class=\"mtk7\">*</span><span class=\"mtk1\"> div_term)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    pe[:, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">::</span><span class=\"mtk4\">2</span><span class=\"mtk1\">] </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> np.cos(position </span><span class=\"mtk7\">*</span><span class=\"mtk1\"> div_term)  </span><span class=\"mtk3\"># [self._max_len, d_feature]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> self._use_bfloat16:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      pe </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> pe.astype(jnp.bfloat16)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    w </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> jnp.array(pe)  </span><span class=\"mtk3\"># Trainable parameters, initialized above.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># ...</span></span></span></code></pre>\n<p><code>init_weights_and_state</code> 함수는 <code>ShapeDtype</code> 객체를 입력받아서 임베딩 크기 <code>(max_len, d_feature)</code> 크기의 벡터 <code>pe</code>를 초기화 한다. <code>pe</code> 벡터의 짝수 행에는 <code>positon * div_term</code>의 sine 값을 할당하고 홀수 행에는 cosine 값을 할당한다. 이 값을 <code>weights</code>로 전달해 함수<code>forward</code>에서 <code>emb</code> 값으로 입력값에 더해 전달하고 있다. 즉 사인과 코사인 값으로 위치정보를 인코딩해 입력값에 더하는 방식으로 positional encoding을 수행한다.</p>\n<br>\n<h3>📣 Encoder Self-Attention</h3>\n<p>인코더는 셀프-어텐션 레이어를 활용한다. 셀프-어텐션은 주어진 데이터의 부분값과 다른 부분들의 관계를 파악하는 방법이다. 즉 문장 데이터에서 셀프-어텐션은 문장 내의 단어 문맥을 파악한다. 앞서 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>의 값은 어텐션에 따라 다르다고 했는데, 셀프-어텐션 레이어에서는 모든 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>가 같은 시퀀스, 즉 인코더의 이전 레이어의 결과값에서 온다. 주어진 문장이 있을 때, 임의의 단어 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span>에 대응하는 임베딩에 대한 가중치를 학습할 수 있다. 임베딩에 가중치를 곱해 얻은 쿼리 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span>에 대해 모든 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>∈</mo><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">k \\in K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>와 dot product로 비교해서 유사도 점수를 얻을 수 있다. 그 다음 softmax 함수를 통해 모든 가중치를 더해서 1이 되는 양수값으로 변환한다. 그 후 두번째 dot product로 단어 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span>에 대응하는 다른 단어들의 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span>값들을 구해 다시 학습한 가중치 행렬을 곱함으로서 모든 가중치 합을 구한다. 이것이 단어 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span>에 대한 어텐션이다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1042px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 106%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAABYlAAAWJQFJUiTwAAABvElEQVR42pVU21KDMBD1///Ar/Cx4/gDvqnTOlo6cimUIoU2XEpaCDlO0qYm9GJkhtmQJWfP7p7sHecc4hFWXyvb973hF99qfen/u1uAXdehqirDL771IP8C3O/3aJrG8Nd1bQ84BA7DEKvVSq4ViOu6KMvSnqEOmOc5CCHGoTRNJcvhmZsMlc2yDNvt1tjfbDZGELV/k6FiMp1OURSFkfJisYDjOEYg/b3YFMaYBJxMJpKRDuh5ngyk1/EqoG4Vm2HKokkqyBDsumyObObzOfIsNwB93z+VwRqwIzuwHZOprZIUYEBHW+mbOTMEQSBLIEozBL5cw7pFlVOE8wBkTdBtW3QNQ5Gs8f42lk2J4/jsFp0DwtSg636BFAeJkHWGNAplXQVDSuntpgwbItIJo6VsSkXWWHreoVHxAkmS2NVQDQQhiR2leHkeYfr5gTyOwQ99kmAiXWtA1vf4Xi4xe3rE6OEerxPnoMOjP4oiqdE/AY2UGUdTNvCDEJTujr7+dIPsU+b6IOUIAv93fPX8lLIVwzMLLnWoJkuvid2+hoNRNB6Pz4aDmIdCNmrPniHnUott2xr7IsAlQSvAH3SSbE0e/6v6AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"transformer attention2\"\n        title=\"\"\n        src=\"/static/eb35de3808469f23000ff41fd4fd1080/5819f/transformer-attention2.png\"\n        srcset=\"/static/eb35de3808469f23000ff41fd4fd1080/5a46d/transformer-attention2.png 300w,\n/static/eb35de3808469f23000ff41fd4fd1080/0a47e/transformer-attention2.png 600w,\n/static/eb35de3808469f23000ff41fd4fd1080/5819f/transformer-attention2.png 1042w\"\n        sizes=\"(max-width: 1042px) 100vw, 1042px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Self-attention, Vaswani et al., 2017</p>\n<p>위 그림은 <em>\"making\"</em> 단어에 대한 어텐션을 표현하고 있다. 위 어텐션의 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>는 모두 한 문장 _\"It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult. <EOS> <pad> ...\"_에서 얻어진다. 다른 색깔은 다른 head를 나타내며 색이 선명할수록 관계도가 높다. _\"making\"_과 연관된 head는 <em>\"making ... more difficult\"</em> 구문을 완성한다.</p>\n<p>물론 효율을 위해 우리는 행렬 단위로 어텐션을 연산한다. 주어진 문장의 단어 임베딩이 임베딩 차원 emb에 대해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub><mo separator=\"true\">,</mo><mi>e</mi><mi>m</mi><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n_{seq}, emb)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">se</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">mb</span><span class=\"mclose\">)</span></span></span></span></span> 차원이라고 하자. 우리는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>e</mi><mi>m</mi><mi>b</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(emb, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">mb</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>차원의 가중치 행렬 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span></span></span></span></span></span></span></span>, 그리고 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></span></span></span></span></span></span></span>을 학습한다. 단어에 대해 했던 것과 마찬가지로 임베딩 행렬에 가중치 행렬을 곱해서 각각 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n_{seq}, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">se</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 차원의 행렬 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, 그리고 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>를 도출할 수 있다. 이후의 어텐션 연산은 scaled-dot product 어텐션에서 살펴본 것과 같다. Multi-head 셀프-어텐션을 실행한다면, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi><mo>∈</mo><msub><mi>n</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">i \\in n_{heads}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6986em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>에 대해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">W^Q_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2361em;vertical-align:-0.2769em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9592em;\"><span style=\"top:-2.4231em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.1809em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2769em;\"><span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">W^K_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1em;vertical-align:-0.2587em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2587em;\"><span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">W^V_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1em;vertical-align:-0.2587em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2587em;\"><span></span></span></span></span></span></span></span></span></span></span>를 훈련하고 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Q</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">Q_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>K</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">K_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">V_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>로 어텐션을 연산한 후, 어텐션 결과값 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">Z_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>를 결합한 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Z</mi></mrow><annotation encoding=\"application/x-tex\">Z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span></span></span></span></span>에 학습한 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>v</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n_{seq}, d_v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">se</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 차원의 가중치 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding=\"application/x-tex\">W^O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span></span></span></span></span></span></span></span> 행렬을 곱해 최종적으로 multi-head 어텐션을 만들 수 있다.</p>\n<br>\n<p>📂 다음 코드는 Trax 라이브러리의 <code>Attention</code> 모델로, Multi-Head 셀프-어텐션을 수행한다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"5\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">Attention</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">d_feature</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk4\">0.0</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk11\">&#39;train&#39;</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk11\">&quot;&quot;&quot;Returns a layer that maps `(vectors, mask)` to `(new_vectors, mask)`.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  This layer type represents one pass of multi-head self-attention, from vector</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  set to vector set, using masks to represent out-of-bound (e.g., padding)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  positions. ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> cb.Serial(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      cb.Select([</span><span class=\"mtk4\">0</span><span class=\"mtk1\">, </span><span class=\"mtk4\">0</span><span class=\"mtk1\">, </span><span class=\"mtk4\">0</span><span class=\"mtk1\">]),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      AttentionQKV(d_feature, </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk1\">n_heads, </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  )</span></span></span></code></pre>\n<p>디코더에서 살펴보겠지만, <code>AttentionQKV</code>는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>를 다른 입력에서 가져올 수 있다. 따라서 셀프-어텐션을 구현하기 위해 <code>Attention</code>은 <code>Select</code>로 첫번째 입력값을 3개로 복제한 값을 <code>AttentionQKV</code>에 전달한다.</p>\n<p>또 인코더의 셀프-어텐션은 <strong>Padding Mask</strong>를 활용한다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"6\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">PaddingMask</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">pad</span><span class=\"mtk7\">=</span><span class=\"mtk4\">0</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk11\">&quot;&quot;&quot;Returns a layer that maps integer sequences to padding masks.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  The layer expects as input a batch of integer sequences. The layer output is</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  an N-D array that marks for each sequence position whether the integer (e.g.,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  a token ID) in that position represents padding -- value ``pad`` -- versus</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  text/content -- all other values. The padding mask shape is</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  (batch_size, 1, 1, encoder_sequence_length), such that axis 1 will broadcast</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  to cover any number of attention heads and axis 2 will broadcast to cover</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  decoder sequence positions. ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">f</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">x</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> </span><span class=\"mtk15\">len</span><span class=\"mtk1\">(x.shape) </span><span class=\"mtk7\">!=</span><span class=\"mtk1\"> </span><span class=\"mtk4\">2</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk7\">raise</span><span class=\"mtk1\"> </span><span class=\"mtk15 mtki\">ValueError</span><span class=\"mtk1\">(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          </span><span class=\"mtk15 mtki\">f</span><span class=\"mtk11\">&#39;Input to PaddingMask must be a 2-D array with shape &#39;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          </span><span class=\"mtk15 mtki\">f</span><span class=\"mtk11\">&#39;(batch_size, sequence_length); instead got shape </span><span class=\"mtk4\">{</span><span class=\"mtk1\">x.shape</span><span class=\"mtk4\">}</span><span class=\"mtk11\">.&#39;</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    batch_size </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.shape[</span><span class=\"mtk4\">0</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    sequence_length </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> x.shape[</span><span class=\"mtk4\">1</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    content_positions </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> (x </span><span class=\"mtk7\">!=</span><span class=\"mtk1\"> pad)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> content_positions.reshape((batch_size, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, sequence_length))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> Fn(</span><span class=\"mtk15 mtki\">f</span><span class=\"mtk11\">&#39;PaddingMask(</span><span class=\"mtk4\">{</span><span class=\"mtk1\">pad</span><span class=\"mtk4\">}</span><span class=\"mtk11\">)&#39;</span><span class=\"mtk1\">, f)</span></span></span></code></pre>\n<p>즉 패딩 토큰 <code>pad</code>로 설정된 값과 같은 부분을 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span></span>으로 바꾼다. 출력 차원은 <code>(batch_size, 1, 1, sequence_length)</code>으로, 어텐션과 차원을 맞추기 위해 1번과 2번 축을 추가한다.</p>\n<br>\n<br>\n<h2>2. Decoder</h2>\n<p>트랜스포머의 디코더는 두 가지 어텐션을 거친다. 첫 번째 어텐션은 인코더에서와 같은 셀프-어텐션이고, 두번째는 인코더-디코더 어텐션이다. 인코더만 사용해 모델을 만들 수 있었던 것처럼, 디코더만 사용해서 모델을 형성할 수도 있다. 디코더만 사용할 때에는 Multi-Head 셀프-어텐션만 사용할 수 있다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 49.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACU0lEQVR42mWS6U8aARDF+bubpm2apv2mTWwN1noQa008KgikXrWK1gNQUEFg3QXkcpVjd0H2xl/DmqZJ+5LJy8wkL28On67rFItFyuUy1WoVWZY9HuaSJGFZFv/CcmxM28J9HPzX8zmOQ6fTQbgWyOVz5PJXCIJAq9Wi3W4z7Otqj15T5aGlod11kLIC+fMsdzcNTOWBfrvrhWs5+P4om67OcWaf3eQWqtH2arqhY/VNEh+j/Hj9hbUXkyw/Gyf8aoqV534238yRHAmTHA1z9HaZdqH+JOi6rjdiMBRkcWnRG3UIRengOi7afY+62CCXypFL57hIXHqROc0iXopIWQkpW8Lom0+ClqGTlepMrl8yFkxwJso8Ohaq1mNgG1hXYdqHAfLRMTLBUTLBES5XRxCiY5S3JyhtTdA/mQWtim8wGKCqKuK1wEZ0jfVIEOlawHYcut0uumEQinxnJjDP9NQMU5+nmZkOeByY+8rCUpDF1Qhfl4LU6o0nh33DolpIE5t7x/bkS27OY9gD6GoqhuWwdt4icFDh0/oF/ugZ45FTPoTi+KMpJtYvmN2TmI/fU1VMfJ47UfT2lssXKJVvPGdDqJqGO7yyotKqN6gVS8iVGupdE0W+R7lr0m7INGsNTFXDtW18qqJQqVXpVGR2/d/YeL+AIt4+HaWjYFoG8eI+G+kQkfgKG6kQx9Iu8XKMk9IeicoB6dtjjso/afbkv2/z6AwQUlmyJ2nMnu7VDN3Adm0ubuMcijv8KuxwKOwQu9rkIL/l8XFxl7R8SLIeQzFa/AZCUcZZStMIKgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"transformer decoder\"\n        title=\"\"\n        src=\"/static/88080a9fdad0d92f75e9cce5c0b7a291/c1b63/transformer-decoder.png\"\n        srcset=\"/static/88080a9fdad0d92f75e9cce5c0b7a291/5a46d/transformer-decoder.png 300w,\n/static/88080a9fdad0d92f75e9cce5c0b7a291/0a47e/transformer-decoder.png 600w,\n/static/88080a9fdad0d92f75e9cce5c0b7a291/c1b63/transformer-decoder.png 1200w,\n/static/88080a9fdad0d92f75e9cce5c0b7a291/ce92a/transformer-decoder.png 1459w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Decoder structure, from deeplearning.ai</p>\n<p>인코더에서와 마찬가지로 디코더에서도 입력값 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>를 임베드하고 Positional Encoding 처리를 한 후에 Residual을 포함한 1️⃣ Multi-Head Attention과 2️⃣ FeedForward 레이어를 거친다. 디코더 블럭을 여러번 거친 후에 훈련 가능한 Linear 레이어와 Softmax 함수를 거치는데, 이 부분은 수행하고자 하는 과제에 따라 변경할 수 있다.</p>\n<br>\n<p>📂 다음 코드는 Trax 라이브러리의 <code>TransformerLM</code>로, 디코더만 구현된 함수이다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"7\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">TransformerLM</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">vocab_size</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">d_model</span><span class=\"mtk7\">=</span><span class=\"mtk4\">D_MODEL</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">d_ff</span><span class=\"mtk7\">=</span><span class=\"mtk4\">D_FF</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">n_layers</span><span class=\"mtk7\">=</span><span class=\"mtk4\">N_LAYERS</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk4\">N_HEADS</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">max_len</span><span class=\"mtk7\">=</span><span class=\"mtk4\">MAX_SEQUENCE_LENGTH</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk4\">DROPOUT_RATE</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">dropout_shared_axes</span><span class=\"mtk7\">=</span><span class=\"mtk4\">DROPOUT_SHARED_AXES</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk4\">MODE</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">ff_activation</span><span class=\"mtk7\">=</span><span class=\"mtk4\">FF_ACTIVATION_TYPE</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_DecBlock</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> _DecoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         mode, ff_activation)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Serial(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.ShiftRight(</span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode),  </span><span class=\"mtk3\"># Teacher Forcing</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Embedding(vocab_size, d_model),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.PositionalEncoding(</span><span class=\"mtk19 mtki\">max_len</span><span class=\"mtk7\">=</span><span class=\"mtk1\">max_len, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      [_DecBlock() </span><span class=\"mtk7\">for</span><span class=\"mtk1\"> _ </span><span class=\"mtk7\">in</span><span class=\"mtk1\"> </span><span class=\"mtk15\">range</span><span class=\"mtk1\">(n_layers)],</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Dense(vocab_size),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  )</span></span></span></code></pre>\n<p><code>_DecoderBlock</code>은 다음과 같다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"8\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_DecoderBlock</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">d_model</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">d_ff</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">dropout_shared_axes</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  </span><span class=\"mtk19 mtki\">ff_activation</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> [</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Residual(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _CausalAttention(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      ),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Residual(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _FFBlock(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      ),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  ]</span></span></span></code></pre>\n<p><code>TransformerLM</code> 함수는 Teacher Forcing을 거쳐 임베딩, positional encoding 처리 후 <code>n_layers</code>만큼의 디코더 블럭을 거쳐 <code>tl.LayerNorm()</code>과 <code>vocab_size</code>만큼의 <code>tl.Dense()</code> 레이어을 통과하는 구조를 가지고 있다. 결과적으로 사전에 주어진 단어들을 통해 다음에 올 단어를 vocabulary 내의 토큰으로 예측하는 언어 모델(language model)을 수행한다.</p>\n<br>\n<h3>🔆 Teacher Forcing</h3>\n<p>디코더 블럭에 들어가기에 앞서, Teacher Forcing 기법을 활용해 모델의 훈련 속도를 높일 수 있다. RNN 모델인 Seq2Seq 모델은 바로 전 레이어의 예측 값을 다음 레이어의 입력값으로 사용한다. 때문에 모델 훈련 초기의 (덜 훈련된) 나쁜 예측 값이 계속해서 모델 훈련에 영향을 줄 가능성이 크다. 이런 문제를 완화하기 위해 이전 레이어의 예측값이 아닌 실제 타켓 값을 다음 레이어의 입력값으로 사용하는 것을 Teacher Forcing이라고 한다. 마치 선생님이 직접 이렇게 하라고 지도해주는 것과 같다. 훈련 초기에 타겟 값에 수렴하는 것을 돕기 때문에, 이 방법으로 모델 훈련 속도를 획기적으로 높일 수 있다.</p>\n<p>위의 코드에서 나타난 <code>ShiftRight</code> 레이어가 teacher forcing 역할을 한다. 즉 (한 시점 미래 값인) 바로 오른 쪽 값을 가져오는 것으로 학습하는 모델을 교정할 수 있다. 위의 코드에서 <code>mode</code>가 인자로 들어간 이유도, 학습 외에 예측을 수행할 때는 teacher forcing을 적용하지 않기 때문이다.</p>\n<p>그렇지만 Teacher Forcing은 모델을 훈련하는 과정에서 실제 타겟값을 노출하기 때문에 모델의 안정성, 즉 보다 일반적인 예에 대한 예측 능력이 떨어질 수 있다. 이렇게 훈련 중에 Label에 노출되는 경우를 <strong>Exposure Bias</strong>가 있다고 한다. 이 때문에 curriculum learning 방법에서는 FeedForward의 학습 초기에만 이전 레이어의 예측값을 타겟 값으로 대체하고 학습 후기에는 대체 하지 않는다.</p>\n<br>\n<h3>📣 Causal Self-Attention</h3>\n<p>디코더의 입력값에 대한 어텐션을 실행할 때도 어텐션에서와 마찬가지로 문맥을 위해 셀프-어텐션을 실행할 수 있다. 단, 디코더의 셀프-어텐션은 <strong>Causal Mask</strong>가 필요하다. 앞에서와 같이 기계 번역 과제를 고려해보자. RNN은 디코더의 입력값에 순차적으로 접근해 매번 인코더의 결과값과 해당 시점의 디코더 입력값을 비교할 것이다. 그렇지만 어텐션은 모든 시점의 데이터를 한번에 볼 수 있으므로 특정 시점에서 모델의 타깃인 오른쪽 값에 대한 접근(attend)을 방지해야 한다.</p>\n<br>\n<p>📂 다음 코드는 Trax의 <code>_causal_mask</code>로, 인자로 받은 <code>length</code> 길이 정방 행렬의 lower triangular 행렬을 반환한다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"9\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_causal_mask</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">length</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># Not all backends define jnp.tril. However, using np.tril is inefficient</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># in that it creates a large global constant. </span><span class=\"mtk7\">TODO</span><span class=\"mtk3\">(kitaev): try to find an</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># alternative that works across all backends.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> fastmath.is_backend(fastmath.Backend.</span><span class=\"mtk4\">JAX</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> jnp.tril(jnp.ones((</span><span class=\"mtk4\">1</span><span class=\"mtk1\">, length, length), </span><span class=\"mtk19 mtki\">dtype</span><span class=\"mtk7\">=</span><span class=\"mtk1\">np.bool_), </span><span class=\"mtk19 mtki\">k</span><span class=\"mtk7\">=</span><span class=\"mtk4\">0</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">else</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> np.tril(np.ones((</span><span class=\"mtk4\">1</span><span class=\"mtk1\">, length, length), </span><span class=\"mtk19 mtki\">dtype</span><span class=\"mtk7\">=</span><span class=\"mtk1\">np.bool_), </span><span class=\"mtk19 mtki\">k</span><span class=\"mtk7\">=</span><span class=\"mtk4\">0</span><span class=\"mtk1\">)</span></span></span></code></pre>\n<p><code>DotProductCausalAttention</code> 어텐션은 1개 Head 어텐션을 구현하는 함수로 <code>CausalAttention</code>으로 구현될 수 있다. 주목해서 볼 점은 모델이 예측을 수행하지 않을 때만 Causal Mask를 활용하는 점이다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"10\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">class</span><span class=\"mtk1\"> </span><span class=\"mtk5 mtku\">DotProductCausalAttention</span><span class=\"mtk1\">(</span><span class=\"mtk6 mtki mtku\">base</span><span class=\"mtk1\">.</span><span class=\"mtk6 mtki mtku\">Layer</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk11\">&quot;&quot;&quot;Layer that computes attention strengths by masking out the &quot;future&quot;.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  Causal attention uses masking to prevent a given sequence position from</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  attending to positions greater than / following it. This is used, for</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  example, when training autoregressive sequence models, or when decoding a</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  sequence symbol by symbol.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  This layer performs the core per-head attention calculation. The layer</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  assumes that any splitting into attention heads precedes it, and that any</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  merging of attention heads will follow it.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">forward</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">self</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">inputs</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk11\">&quot;&quot;&quot;Returns attention-computed activations.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">    Args:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">      inputs: A (queries, keys, values) tuple.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">    &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    q, k, v </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> inputs</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> self._mode </span><span class=\"mtk7\">==</span><span class=\"mtk1\"> </span><span class=\"mtk11\">&#39;predict&#39;</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      self.state, mask </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> _fast_inference_update_state(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          inputs, self.state,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          </span><span class=\"mtk19 mtki\">mask_for_predict</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mask_for_predict)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">else</span><span class=\"mtk1\">:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      sequence_length </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> q.shape[</span><span class=\"mtk7\">-</span><span class=\"mtk4\">2</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      mask </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> _causal_mask(sequence_length)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    activations, attn_strengths </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> _per_head_attention(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        q, k, v, mask, </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk1\">self._dropout, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">self._mode, </span><span class=\"mtk19 mtki\">rng</span><span class=\"mtk7\">=</span><span class=\"mtk1\">self.rng)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\">#...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> activations</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk3\"># ...</span></span></span></code></pre>\n<br>\n<h3>📣 Encoder-Decoder Attention</h3>\n<p>이제 디코더의 입력값과 인코더의 입력값을 분석하는 과제가 남았다. 인코더-디코더 블럭의 입력값은 <code>(vec_d, mask, vec_e)</code>로 패딩 마스크 <code>mask</code>를 이용해 패딩된 값에 대해서는 어텐션을 수행하지 않는다.</p>\n<br>\n<p>📂 다음 코드는 Trax 라이브러리의 <code>AttentionQKV</code> 함수로, <code>Attention</code>이 셀프-어텐션만 수행하는 것과 달리 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>와 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo>−</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">K-V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>를 다른 데이터에서 가져오는 것을 허용한다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"11\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">AttentionQKV</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">d_feature</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk4\">0.0</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk11\">&#39;train&#39;</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                 </span><span class=\"mtk19 mtki\">cache_KV_in_predict</span><span class=\"mtk7\">=</span><span class=\"mtk4\">False</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">q_sparsity</span><span class=\"mtk7\">=</span><span class=\"mtk4\">None</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                 </span><span class=\"mtk19 mtki\">result_sparsity</span><span class=\"mtk7\">=</span><span class=\"mtk4\">None</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> cb.Serial(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      cb.Parallel(_SparsifiableDense(q_sparsity),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  _CacheableDense(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                  _CacheableDense()),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      _PureAttention(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      _SparsifiableDense(result_sparsity),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  )</span></span></span></code></pre>\n<p><code>cb.Parallel</code>은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>에 해당하는 입력을 밀도 <code>q_sparsity</code>를 가지는 행렬로, 그리고 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>와 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>에 해당하는 입력을 <code>d_feature</code>만큼의 <code>Dense</code> 레이어로 두고, <code>_PureAttention</code>과 일종의 훈련가능한 <code>Dense</code> 레이어를 통과한다.</p>\n<p>최종적으로 Trax 라이브러리의 <code>_EncoderDecoderBlock</code> 함수를 보자.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"12\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_EncoderDecoderBlock</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">d_model</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         </span><span class=\"mtk19 mtki\">d_ff</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         </span><span class=\"mtk19 mtki\">dropout_shared_axes</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         </span><span class=\"mtk19 mtki\">ff_activation</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_Dropout</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Dropout(</span><span class=\"mtk19 mtki\">rate</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout, </span><span class=\"mtk19 mtki\">shared_axes</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout_shared_axes, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_AttentionQKV</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.AttentionQKV(d_model, </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk1\">n_heads, </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                           </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode, </span><span class=\"mtk19 mtki\">cache_KV_in_predict</span><span class=\"mtk7\">=</span><span class=\"mtk4\">True</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_CausalAttention</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.CausalAttention(d_model, </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk1\">n_heads, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_FFBlock</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> _FeedForwardBlock(d_model, d_ff, dropout, dropout_shared_axes, mode,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                             ff_activation)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> [                             </span><span class=\"mtk3\"># vec_d masks vec_e</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Residual(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _CausalAttention(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      ),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Residual(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.Select([</span><span class=\"mtk4\">0</span><span class=\"mtk1\">, </span><span class=\"mtk4\">2</span><span class=\"mtk1\">, </span><span class=\"mtk4\">2</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk4\">2</span><span class=\"mtk1\">]),  </span><span class=\"mtk3\"># vec_d vec_e vec_e masks vec_e</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _AttentionQKV(),             </span><span class=\"mtk3\"># vec_d masks vec_e</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      ),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Residual(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _FFBlock(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      ),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  ]</span></span></span></code></pre>\n<p><code>_EncoderDecoderBlock</code>은 디코더 벡터, 마스크, 인코더 벡터 쌍인 <code>(vec_d, masks, vec_e)</code>를 입력받는다. 여기서 디코더의 두가지 어텐션을 모두 실행하고 있음에 유의한다. 첫째로 <code>_CausalAttention</code>을 적용한 후 <code>(vec_d, vec_e, vec_e, masks, vec_e)</code>로 데이터를 정렬한다. 앞에서 부터 세 개 입력이 <code>_AttentionQKV()</code>레이어를 거쳐서 입력값과 같은 차원인 <code>(vec_d, masks, vec_e)</code>를 얻어 FeedForward 블럭을 거친다. 즉 인코더-디코더 어텐션에서는 디코더 벡터를 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></span>로, 인코더 벡터를 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>와 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span>로 입력받는 것을 확인할 수 있다.</p>\n<br>\n<br>\n<h2>4. Overall</h2>\n<p>다음은 인코딩과 디코딩을 직관적으로 보여주는그림으로, 영어 문장을 프랑스어 문장으로 번역하는 예시를 보이고있다.</p>\n<p><img src=\"https://3.bp.blogspot.com/-aZ3zvPiCoXM/WaiKQO7KRnI/AAAAAAAAB_8/7a1CYjp40nUg4lKpW7covGZJQAySxlg8QCLcBGAs/s1600/transform20fps.gif\" alt=\"\"></p>\n<p>Cool gif from Google AI blog</p>\n<p>Transformer 모델은 인코더나 디코더만으로도 쓰임이 있지만, 기계 번역과 같은 시퀀스-투-시퀀스 과제에는 인코더와 디코더를 모두 활용해야 한다. 아래의 <code>Transformer</code> 모델은 앞서 살펴 본 인코더와 디코더 블럭을 활용해 전체 트랜스포머 모델을 반환한다.</p>\n<br>\n<p>📂 다음 코드는 Trax 라이브러리의 <code>Transformer</code> 모델이다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"13\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">Transformer</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">input_vocab_size</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">output_vocab_size</span><span class=\"mtk7\">=</span><span class=\"mtk4\">None</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">d_model</span><span class=\"mtk7\">=</span><span class=\"mtk4\">D_MODEL</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">d_ff</span><span class=\"mtk7\">=</span><span class=\"mtk4\">D_FF</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">n_encoder_layers</span><span class=\"mtk7\">=</span><span class=\"mtk4\">N_LAYERS</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">n_decoder_layers</span><span class=\"mtk7\">=</span><span class=\"mtk4\">N_LAYERS</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">n_heads</span><span class=\"mtk7\">=</span><span class=\"mtk4\">N_HEADS</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">max_len</span><span class=\"mtk7\">=</span><span class=\"mtk4\">MAX_SEQUENCE_LENGTH</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">dropout</span><span class=\"mtk7\">=</span><span class=\"mtk4\">DROPOUT_RATE</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">dropout_shared_axes</span><span class=\"mtk7\">=</span><span class=\"mtk4\">DROPOUT_SHARED_AXES</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk4\">MODE</span><span class=\"mtk1\">,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                </span><span class=\"mtk19 mtki\">ff_activation</span><span class=\"mtk7\">=</span><span class=\"mtk4\">FF_ACTIVATION_TYPE</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk11\">&quot;&quot;&quot;Returns a full Transformer model.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  This model is an encoder-decoder that performs tokenized string-to-string</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  (&quot;source&quot;-to-&quot;target&quot;) transduction:</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk11\">  &quot;&quot;&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># ...</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_Dropout</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Dropout(</span><span class=\"mtk19 mtki\">rate</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout, </span><span class=\"mtk19 mtki\">shared_axes</span><span class=\"mtk7\">=</span><span class=\"mtk1\">dropout_shared_axes, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_EncBlock</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> _EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                         mode, ff_activation)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_Encoder</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    encoder </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> tl.Serial(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        in_embedder,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        tl.PositionalEncoding(</span><span class=\"mtk19 mtki\">max_len</span><span class=\"mtk7\">=</span><span class=\"mtk1\">max_len, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">encoder_mode),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        [_EncBlock() </span><span class=\"mtk7\">for</span><span class=\"mtk1\"> _ </span><span class=\"mtk7\">in</span><span class=\"mtk1\"> </span><span class=\"mtk15\">range</span><span class=\"mtk1\">(n_encoder_layers)],</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    )</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Cache(encoder) </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> mode </span><span class=\"mtk7\">==</span><span class=\"mtk1\"> </span><span class=\"mtk11\">&#39;predict&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk7\">else</span><span class=\"mtk1\"> encoder</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">_EncDecBlock</span><span class=\"mtk1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> _EncoderDecoderBlock(d_model, d_ff, n_heads, dropout,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">                                dropout_shared_axes, mode, ff_activation)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># Input to model is encoder-side tokens and decoder-side tokens: tok_d, tok_e</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk3\"># Model output is decoder-side vectors and decoder-side tokens: vec_d  tok_d</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> tl.Serial(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Select([</span><span class=\"mtk4\">0</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">]),  </span><span class=\"mtk3\"># Copies decoder tokens for use in loss.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk3\"># Encode.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Branch([], tl.PaddingMask()),  </span><span class=\"mtk3\"># tok_e masks tok_d tok_d</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      _Encoder(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk3\"># Decode.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Select([</span><span class=\"mtk4\">2</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk4\">0</span><span class=\"mtk1\">]),  </span><span class=\"mtk3\"># Re-orders inputs: tok_d masks vec_e .....</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.ShiftRight(</span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      out_embedder,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      _Dropout(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.PositionalEncoding(</span><span class=\"mtk19 mtki\">max_len</span><span class=\"mtk7\">=</span><span class=\"mtk1\">max_len, </span><span class=\"mtk19 mtki\">mode</span><span class=\"mtk7\">=</span><span class=\"mtk1\">mode),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Branch([], tl.EncoderDecoderMask()),  </span><span class=\"mtk3\"># vec_d masks ..... .....</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      [_EncDecBlock() </span><span class=\"mtk7\">for</span><span class=\"mtk1\"> _ </span><span class=\"mtk7\">in</span><span class=\"mtk1\"> </span><span class=\"mtk15\">range</span><span class=\"mtk1\">(n_decoder_layers)],</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.LayerNorm(),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Select([</span><span class=\"mtk4\">0</span><span class=\"mtk1\">], </span><span class=\"mtk19 mtki\">n_in</span><span class=\"mtk7\">=</span><span class=\"mtk4\">3</span><span class=\"mtk1\">),  </span><span class=\"mtk3\"># Drops masks and encoding vectors.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk3\"># Map vectors to match output vocab size.</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      tl.Dense(output_vocab_size),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  )</span></span></span></code></pre>\n<p><code>Transformer</code> 는 인코더에 입력되는 토큰과 디코더에 입력되는 토큰 쌍 <code>(tok_d, tok_e)</code>를 입력받아 디코더 벡터와 디코더 토큰 쌍 <code>(vec_d, tok_d)</code>를 반환한다. <code>tl.Branch</code>로 입력값과 패딩마스크를 생성한 후 <code>_Encoder()</code>로 인코딩을 실행한다. <code>_Encoder</code>는 <code>n_encoder_layers</code>개의 인코더 블럭 <code>_EncoderDecoderBlock</code>을 포함하도록 정의되어 있다. 인코딩을 거치면 데이터는 <code>(vec_e, masks, tok_d)</code>가 되며 <code>tl.Select</code>로 순서를 뒤집어 teacher forcing과 positional encoding을 실행한다. 두번째 <code>tl.Branch</code>로 <code>(tok_d, masks)</code>를 인코더-디코더 블럭에 입력하며, 이 외의 값들은 이후 <code>tl.Select</code>로 제외시키는 것을 알 수 있다. <code>_EncoderDecoderBlock</code>은 앞에서 살펴본 대로다. 이로써 <code>Transformer</code>함수를 불러오는 것만으로  트랜스포머를 구현할 수 있다.</p>\n<br>\n<br>\n<h2>나가며</h2>\n<p>여러 내용을 다루다보니 글이 길어졌다. 트랜스포머 모델은 긴 시퀀스에서 맥락을 추출하는데에 사용되는 모델로 널리 쓰이고 있지만, 짧은 시퀀스를 분석하거나 맥락을 구하기 어려운 문제에 대해서는 적합하지 않을 수 있다. 한편으로는 트랜스포머 모델을 이미지에 적용한 사례나 다양한 과제를 한번에 수행하는 T5, 더 긴 시퀀스에 대해 효율적(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(NlogN)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">Nl</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span></span>)으로 학습하는 리포머 모델 등 다양한 버전이 등장하고 있으므로, 트랜스포머의 기본적인 구조를 이해하는 것이 중요할 것이다.</p>\n<p>글로 정리하면서 나의 맹점에 대해 알 수 있었다. Residual이 왜 필요한지, 인코더나 디코더 블럭을 왜 여러번 실행하는지, 어텐션에서 학습하는 파라미터는 어느 부분인지 생각하지 않고 넘기다가 논문을 읽으면서 저자의 의도와 history를 조금 더 이해할 수 있었다. 또 글을 쓰면서 Trax 라이브러리의 코드를 부분적으로 들여다봤다. <code>Select()</code>나 <code>Residual()</code>, <code>Branch()</code>로 레이어를 쌓는 부분은 그림이 자연스럽게 떠오르는 개념을 코드로 표현해 직관적이라는 느낌이 들었고, 인코더나 디코더의 일부분을 따로 떼어서 사용하는 각각의 함수가 있어 사용 편의를 고려한 점이 느껴졌다. 큰 프로그램(라이브러리)의 코드이다보니 재사용되는 부분과 조금씩 차이나는 부분, 특히 메서드의 의존도를 미리 디자인해서 큰 그림을 염두에 두고 프로그램을 작성했다는 점이 느껴졌다. 결국 이론과 구현이 모두 중요하고 나름의 깊이가 있다는 것을 알 수 있었다.</p>\n<br>\n<br>\n<h2>참고 자료</h2>\n<ol>\n<li>Natural Language Processing with Attention Models, deeplearning.ai, Coursera, <a href=\"https://www.coursera.org/specializations/natural-language-processing\">https://www.coursera.org/specializations/natural-language-processing</a></li>\n<li>Trax Library for Machine Learning, Github, <a href=\"https://github.com/google/trax\">https://github.com/google/trax</a></li>\n<li>Transformers, Google AI blog, <a href=\"https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\">https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</a></li>\n<li>Vaswani et al, 2017, <a href=\"https://arxiv.org/abs/1706.03762\">https://arxiv.org/abs/1706.03762</a></li>\n<li>Jay Alammar on Github page, <a href=\"https://jalammar.github.io/illustrated-transformer/\">https://jalammar.github.io/illustrated-transformer/</a></li>\n</ol>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .abyss { background-color: #000c18; }\n  .abyss .mtku {\n    text-decoration: underline;\n    text-underline-position: under;\n  }\n  .abyss .mtki { font-style: italic; }\n  .abyss .mtk15 { color: #9966B8; }\n  .abyss .mtk1 { color: #6688CC; }\n  .abyss .mtk6 { color: #DDBB88; }\n  .abyss .mtk19 { color: #2277FF; }\n  .abyss .mtk7 { color: #225588; }\n  .abyss .mtk4 { color: #F280D0; }\n  .abyss .mtk11 { color: #22AA44; }\n  .abyss .mtk3 { color: #384887; }\n  .abyss .mtk5 { color: #FFEEBB; }\n  .abyss .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));\n  }\n</style>","frontmatter":{"title":"[Paper/Trax] Transformer, 2017","date":"April 14, 2022"}}},"pageContext":{"slug":"/AI/NLP/transformer/","previous":{"fields":{"slug":"/AI/NLP/naive-bayes/"},"frontmatter":{"title":"텍스트 나이브 베이즈 분류"}},"next":{"fields":{"slug":"/AI/NLP/siamese-nn/"},"frontmatter":{"title":"[Paper] Siamese Neural Network, 2015"}}}},"staticQueryHashes":["1185972000","3231742164"],"slicesMap":{}}