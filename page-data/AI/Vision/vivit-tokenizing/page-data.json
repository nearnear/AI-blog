{"componentChunkName":"component---src-templates-blog-post-js","path":"/AI/Vision/vivit-tokenizing/","result":{"data":{"allMarkdownRemark":{"totalCount":53},"markdownRemark":{"id":"15455dcc-bf8a-53d3-8c9e-d20082901c09","html":"<h3>비디오 트랜스포머인 ViViT의 토큰화 방법 두가지를 구현하고 비교해보자.</h3>\n<p>비디오 같은 3D 비전 데이터셋은 2D 이미지 데이터셋과 유사하지만 시간 차원을 하나 더 가지고 있다. 이미지 데이터를 트랜스포머로 다루는 ViT에서 토큰화 방법이 중요했던 만큼, ViViT에서도 토큰화 방법이 중요한 영향을 끼치지 않을까하는 질문에서 시작해 논문 <a href=\"https://arxiv.org/abs/2103.15691\">ViViT: A Video Vision Transformer</a>에 소개된 두가지 토큰화 방법을 비교해보기로 했다. 실험은 각각의 토큰화 방법을 활용한 모델을 같은 데이터셋과 하이퍼파라미터로 학습을 했을 때 수렴하는 여부, 학습과 검증의 accuracy와 loss, 그리고 학습 시간의 차이를 비교했다. <a href=\"https://medmnist.com/\">MedMNIST3D</a>의 6개 데이터셋에 대해 실험했으며, 사전 학습은 진행하지 않았고, 결과의 시각화를 위해 TensorBoard를 사용했다. 전체 코드는 <a href=\"https://github.com/nearnear/vision-studies/blob/main/ViViT/Tokenization_comparison_in_ViViT.ipynb\">깃허브</a>에서 볼 수 있다. 전체 결과 그래프는 <a href=\"https://tensorboard.dev/experiment/PKs2SEeNQLO68B4tB7U8tg\">Tensorboard.dev</a>에서 확인할 수 있다.</p>\n<br>\n<br>\n<h2>1. Uniform Frame Sampling</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 33.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABoUlEQVR42kWRXW8SYRCF+1u9MTFeeGXsX/EKbdI2loYlrUVol7IVWHCBAgKlWT6EwEINVKTCfr7vY1iKTnJmJpPMyTkze1JKhAgAiWOv+fO0xA8ErushhEAIGSIIBJ7v4/s+IkRA4PnYjsvadtnwbGJvk+5y77k+eIEefU3i4xuOlAyXN7foRp0bvRoiW6hz159gxM44ffmKi7fvuNrfJ6EkUfXv2LazJXQcFzWpoF1EuDPOaZXTmJ0x3b5FsdzA7A4oGbc0mybWw5yR2aWtpikqcYqxOIeRA8zeMHQTEm6aD58+EzlJoOlVKrV7SuUaeqFMsVKn+2PIeDLFmkyZTh/IfitzmsqgpNLEUxnOkypa3vivcJPSX3WOogpJ9RpVy6JqOYqlKvVmm2bbpG32uO/06A+GGJUaylmC45MYh8dREpdpvlxlWK1WW8LdMXchA4fAfcK1F3iuQ+CtmP8cM7MsvPUKZ/kbKQXSsf/tOLaN3FkOvxx+ejuYWS1GZp5BW2O5mDMbNZhbdQaGwbjVoJPL8uvxkWEhz8IaP6t4LlLyF5Yx9pnio4KsAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vivit ufs\"\n        title=\"\"\n        src=\"/static/4d5e407a1766e69603d2297c48e902d6/c1b63/vivit-ufs.png\"\n        srcset=\"/static/4d5e407a1766e69603d2297c48e902d6/5a46d/vivit-ufs.png 300w,\n/static/4d5e407a1766e69603d2297c48e902d6/0a47e/vivit-ufs.png 600w,\n/static/4d5e407a1766e69603d2297c48e902d6/c1b63/vivit-ufs.png 1200w,\n/static/4d5e407a1766e69603d2297c48e902d6/d4e7f/vivit-ufs.png 1416w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Uniform Frame Sampling, from the paper.</p>\n<p>Uniform Frame Sampling은 비디오에서 시간에 따른 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>n</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">n_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>개의 2D 프레임을 샘플링한 뒤 2D 합성곱을 실행해서 시간 순으로 쌓는 방법이다 (3D 데이터의 경우 임의의 축을 시간축으로 생각할 수 있다).</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>n</mi><mi>t</mi></msub><mo>=</mo><mo stretchy=\"false\">⌊</mo><mfrac><mi>T</mi><mtext>patch size</mtext></mfrac><mo stretchy=\"false\">⌋</mo><mo>&#x3C;</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">n_t = \\lfloor \\frac{T}{\\text{patch size}} \\rfloor &#x3C; T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.3534em;vertical-align:-0.4811em;\"></span><span class=\"mopen\">⌊</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">patch size</span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4811em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">⌋</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&#x3C;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> 이므로 샘플링 되지 않거나 중복되는 정보가 있을 수 있다. 코드는 다음과 같다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">class</span><span class=\"mtk1\"> </span><span class=\"mtk5 mtku\">UniformFrameSampling</span><span class=\"mtk1\">(</span><span class=\"mtk6 mtki mtku\">layers</span><span class=\"mtk1\">.</span><span class=\"mtk6 mtki mtku\">Layer</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk15\">__init__</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">self</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">embed_dim</span><span class=\"mtk7\">=</span><span class=\"mtk4\">PROJECTION_DIM</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">patch_size</span><span class=\"mtk7\">=</span><span class=\"mtk4\">PATCH_SIZE</span><span class=\"mtk1\">, </span><span class=\"mtk7\">**</span><span class=\"mtk19 mtki\">kwargs</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk15 mtki\">super</span><span class=\"mtk1\">().</span><span class=\"mtk15\">__init__</span><span class=\"mtk1\">(</span><span class=\"mtk7\">**</span><span class=\"mtk1\">kwargs)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        self.patch_size </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> patch_size</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        self.projection2d </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> layers.Conv2D(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">filters</span><span class=\"mtk7\">=</span><span class=\"mtk1\">embed_dim,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">kernel_size</span><span class=\"mtk7\">=</span><span class=\"mtk1\">(patch_size, patch_size),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">strides</span><span class=\"mtk7\">=</span><span class=\"mtk1\">(patch_size, patch_size),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">padding</span><span class=\"mtk7\">=</span><span class=\"mtk11\">&quot;valid&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        )</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        self.concat </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> layers.Concatenate(</span><span class=\"mtk19 mtki\">axis</span><span class=\"mtk7\">=</span><span class=\"mtk4\">1</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        self.flatten </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> layers.Reshape(</span><span class=\"mtk19 mtki\">target_shape</span><span class=\"mtk7\">=</span><span class=\"mtk1\">(</span><span class=\"mtk7\">-</span><span class=\"mtk4\">1</span><span class=\"mtk1\">, embed_dim))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">call</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">self</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">videos</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        t </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> videos.shape[</span><span class=\"mtk4\">1</span><span class=\"mtk1\">]</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        projected_patches </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> []</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk7\">for</span><span class=\"mtk1\"> frame </span><span class=\"mtk7\">in</span><span class=\"mtk1\"> </span><span class=\"mtk15\">range</span><span class=\"mtk1\">(self.patch_size, t, self.patch_size): </span><span class=\"mtk3\"># Sample n_t</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            patch </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> self.projection2d(videos[:, frame])  </span><span class=\"mtk3\"># (B, n_h, n_w, embed_dim)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            _, n_h, n_w, embed_dim </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> patch.shape</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            patch </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> layers.Reshape((</span><span class=\"mtk7\">-</span><span class=\"mtk4\">1</span><span class=\"mtk1\">, </span><span class=\"mtk4\">1</span><span class=\"mtk1\">, n_h, n_w, embed_dim))(patch)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            projected_patches.append(patch)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        projected_patches </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> self.concat(projected_patches)  </span><span class=\"mtk3\"># (B, n_t, n_h, n_w, embed_dim)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        flattened_patches </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> self.flatten(projected_patches)  </span><span class=\"mtk3\"># (B, num_patches, embed_dim)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> flattened_patches</span></span></span></code></pre>\n<p>코드 주석에 차원 변화를 기록했다.</p>\n<br>\n<br>\n<h2>2. Tubelet Embedding</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACEElEQVR42m2S208TURCH+d80Ep+I+gAxovUNb8FXHjReXnwkMYZEYoyigjaKQqQXWwq9WlosFXpxG9qyZdmlW6DQAq3s7me6vQDqJJOcMzO/L3PmTJdhGDQdDEMHDBp2WNc4OtIwE62YaZ16o5Vrh5uxrtMw0A2QxZ/8WFokIayxKhaRtyuU9+sc1n+j6/oxBKjuSBxU1A60BWwW7e+p5CPDpFyDJFxDZEJP8DifE5iZJ2jzEI4kSK9KCDmZTXXH1GQWxikkXS2g3gA2YdtKiqx3CNHejTzbQ8HdQ+hdP8H711gYvI337h1iDx8wfe8R1ik/6vaeqVsXgihryyeAumZeZMFB1jmA6B4g/+0ywZHzfL9xkbiln0VLL/HrfUx2n2HkUh9+b5T9g0Nzxntlmd2ycvrJJnCzxK9UnHxyDiH2kaB1jOjNW4QtVwj1XuDDubM867/K+zcTqKUyalFlQymyHp1ETniOO2wPWciKOLwRQjGBWDJPPJXDG4jinbIxP/qSt09fIJXKbJV3sbnnKaxLpi766jVpu6MJ1PWTHaqEF+PMBRZw+UJ8tnsY+2Rj/KubCYcPT2QFty+M9csM2bzY+WkpsYyymvn7l5uuaxq1Wg21tMVaQWJpJc2sP4x12snj4VGcc36q1eqpvVSWYhTTyf8D26ZpR6aoMZPGeUNWyInSP0vcUOzmc1TkjQ7wD5K0zGqEZj8RAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vivit tubelet embedding\"\n        title=\"\"\n        src=\"/static/1c0311de61fcde40df0603acd678486b/c1b63/vivit-tubelet-embedding.png\"\n        srcset=\"/static/1c0311de61fcde40df0603acd678486b/5a46d/vivit-tubelet-embedding.png 300w,\n/static/1c0311de61fcde40df0603acd678486b/0a47e/vivit-tubelet-embedding.png 600w,\n/static/1c0311de61fcde40df0603acd678486b/c1b63/vivit-tubelet-embedding.png 1200w,\n/static/1c0311de61fcde40df0603acd678486b/bb543/vivit-tubelet-embedding.png 1418w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Tubelet Embedding, from the paper.</p>\n<p>앞선 방법과 달리 Tubelet Embedding은 3D 데이터를 그대로 3D 합성곱으로 토큰화하므로 모든 프레임을 임베딩한다. 또한 그림에 묘사된 것처럼 시간에 대해 선형적으로 프레임의 토큰을 묶기 때문에 시공간 정보를 포함할 수 있다. 이때 패치 크기가 클 수록 하나의 Tubelet(관)은 더 많은 정보를 포함할 것이다. 데이터의 차원을 고려하면 3D 합성곱을 활용하는 방법이 더 직관적으로 여겨지며, 코드도 더 간결하다.</p>\n<pre class=\"grvsc-container abyss\" data-language=\"python\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk15 mtki\">class</span><span class=\"mtk1\"> </span><span class=\"mtk5 mtku\">TubeletEmbedding</span><span class=\"mtk1\">(</span><span class=\"mtk6 mtki mtku\">layers</span><span class=\"mtk1\">.</span><span class=\"mtk6 mtki mtku\">Layer</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk15\">__init__</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">self</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">embed_dim</span><span class=\"mtk7\">=</span><span class=\"mtk4\">PROJECTION_DIM</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">patch_size</span><span class=\"mtk7\">=</span><span class=\"mtk4\">PATCH_SIZE</span><span class=\"mtk1\">, </span><span class=\"mtk7\">**</span><span class=\"mtk19 mtki\">kwargs</span><span class=\"mtk1\">):</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk15 mtki\">super</span><span class=\"mtk1\">().</span><span class=\"mtk15\">__init__</span><span class=\"mtk1\">(</span><span class=\"mtk7\">**</span><span class=\"mtk1\">kwargs)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        self.projection3d </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> layers.Conv3D(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">filters</span><span class=\"mtk7\">=</span><span class=\"mtk1\">embed_dim,</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">kernel_size</span><span class=\"mtk7\">=</span><span class=\"mtk1\">(patch_size, patch_size, patch_size),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">strides</span><span class=\"mtk7\">=</span><span class=\"mtk1\">(patch_size, patch_size, patch_size),</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">            </span><span class=\"mtk19 mtki\">padding</span><span class=\"mtk7\">=</span><span class=\"mtk11\">&quot;valid&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        )</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        self.flatten </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> layers.Reshape(</span><span class=\"mtk19 mtki\">target_shape</span><span class=\"mtk7\">=</span><span class=\"mtk1\">(</span><span class=\"mtk7\">-</span><span class=\"mtk4\">1</span><span class=\"mtk1\">, embed_dim))</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk15 mtki\">def</span><span class=\"mtk1\"> </span><span class=\"mtk6\">call</span><span class=\"mtk1\">(</span><span class=\"mtk19 mtki\">self</span><span class=\"mtk1\">, </span><span class=\"mtk19 mtki\">videos</span><span class=\"mtk1\">):  </span><span class=\"mtk3\"># videos.shape = (B, T, H, W, C)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        projected_patches </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> self.projection3d(videos)  </span><span class=\"mtk3\"># (B, n_t, n_h, n_w, embed_dim)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        flattened_patches </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> self.flatten(projected_patches)  </span><span class=\"mtk3\"># (B, num_patches, embed_dim)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk7\">return</span><span class=\"mtk1\"> flattened_patches</span></span></span></code></pre>\n<p>두 토큰화 방법의 결과 차원이 같은 것을 확인할 수 있다.</p>\n<br>\n<br>\n<h2>3. 비교</h2>\n<p>임베딩의 차이만 있을 뿐, Positional Encoding은 두 임베딩 이후 동일하게 적용했다. 그 후 ViViT Classifier를 정의해 토큰화 방법을 실험하였다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 64.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB2klEQVR42n2S6Y7bMAyE8/5vWPTHbjZNfMmRZF3U5VmQXgRpUtTAwAJEfSSHPOE/n902jNOEYRwxDAOstQ/13iVm3/e/dMqZEGNEKQXGGKzripwzh6JmQk4BtRTkXDDPsyRprb2BHkCGcWBKSTIrpRBTwt4qWtDoTqF5I8FGa2z2ODP0WQ/gc4t8kUtBoYR0XxDUDDtP0NOIFCNa7wh3hRwDSuvSVckZtZaHBafncmutUmmYrkhWywNOQLlIMiJC8B60TiC3HbGsGOXtO7A1BKMFVn8qOPzLUoEA2W+KIDXAD59w4wVOrxIrwNfJcvmUswwqEYlCTNLucV+RKYGiR3IayVlRb+0Aeu9lKNu2yUB4Pdy2HfRegUqi3iqmaZJNkHX5l461yWAo/0MI8oBb4yq22wX++gF3/oUSPXwIWNRdfG21SrXtR/ve31tmKFGCWjVuX3+wKI3r6nFeNthAUoHWBtNtFG/ZNxcithBB5WUo/JVa4a3B+fMCbb34yVN0ISHlA8DeDsOMcVJYTMBNR1yUg0vlHchTNmqBMVYeU0pSdSZC40XnLQgBpWTo9Y758gV9+YD/+o1O/hW4y2qwLwzjHWMvWXyu4tN+JCKSbkryyO4Osgo9JwF+AwF79KXNCtoDAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vivit result nodule\"\n        title=\"\"\n        src=\"/static/82ceb61af315a5404b8192ed2e1029d9/c1b63/vivit-result-nodule.png\"\n        srcset=\"/static/82ceb61af315a5404b8192ed2e1029d9/5a46d/vivit-result-nodule.png 300w,\n/static/82ceb61af315a5404b8192ed2e1029d9/0a47e/vivit-result-nodule.png 600w,\n/static/82ceb61af315a5404b8192ed2e1029d9/c1b63/vivit-result-nodule.png 1200w,\n/static/82ceb61af315a5404b8192ed2e1029d9/b5a09/vivit-result-nodule.png 1360w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB0klEQVR42nVTi26kMAzk/7/xWnVbIJCFNEDeIZnKZtljrzokyxLY4/GMafDfp0KpGaLvIUSPaZqwLAvnGONRUeuvaEIIcM7BGINxHCGlRM4ZFYBPO2xISHthsLZt4ax9AaDBL4AERFNPUGrMOcE6DyFntMOEu9LYc4JeFqybwb7vzJIiUaR0AKKiuS5JbOmjsQ7yPsPNEmmdEfSImqkxYxgktnVjMOc9fIgIMT3ZNk+6pXKR1qSTQqDJOSOmzLmUilOeWWneJrkNyRlkt6GWwqSa6/7eedzlIXoIngHOKLUghgC1bBi1xduXRP/xjnnosU4DatlZ95eVaV3vH0DeM0CKgXWigfTeWgfnPMtCsRmH1Yan6826rhBCQCnFue97bswVsKlAuQybKzvftS2o/t+TwdVlKmSARz6MiRDdgM/3G25/PiBun6i1MDN1n/gKTpcPeQLKqeF1ZS4IAbIT2LRGMhviohHXhRtIEtkPWPTyOJ2ESERS+gt4pX426G+NvRQuJpcpyEVi4q2F7AX0rODmO4xosXVfPOAFkBmGgO9ZIabEzTFeXCZA7zEtBlIbvN0Eum7AOEi+zV8MT6FpEjG9ahQfLp9bcDD7dAT9qvUA/AHR//Pc9OxHxQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vivit result organ\"\n        title=\"\"\n        src=\"/static/10bb1d84def7639d03cb39787fec5240/c1b63/vivit-result-organ.png\"\n        srcset=\"/static/10bb1d84def7639d03cb39787fec5240/5a46d/vivit-result-organ.png 300w,\n/static/10bb1d84def7639d03cb39787fec5240/0a47e/vivit-result-organ.png 600w,\n/static/10bb1d84def7639d03cb39787fec5240/c1b63/vivit-result-organ.png 1200w,\n/static/10bb1d84def7639d03cb39787fec5240/b67f3/vivit-result-organ.png 1338w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Nodule MNIST 3D와 Organ MNIST 3D 데이터셋에 대해, Tubelet Embedding은 검증 정확도와 손실에서 더 나은 결과를 보여줬다. 결과적으로 다양한 데이터셋에서 Tubelet Embedding 방법이 Unifrom Frame Sampling 보다 같은 epoch 대비 더 나은 학습 성과를 보였다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.666666666666664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAABxklEQVR42oWS267aQAxF+f8f5AVVSKUFcplMMjd7PMk+skkoPX1oJGvImCzbe/uE/zwxBDyfTzweDwzDgBgjvPcopVh+27a/4sTMaK1Bz3VdMc+zfUiF7ANZG6gyqlSklNB1HWKK2Nb1o+xmYcD7/Y7L5YLr9YpaK3LOmPwEYsLWGrZIaFMEx2IF/eSRQ7Qm9P8aImLv+pyUqhfrXlETJWek0SOMHsOjx8/ugfs0WJ6J4bsRhchghQpyjqjMf4BH2/pbgWGYME4eLkcEJkRKyJSsqALmycP3I9zg8HQDfgy/ESh/B+4Cq26FIDpKrWAi01e70byeRGTSqGHx6TD/6lHSB1AdO0ZelgVd3yOEgFrFRpHKaCIG7vvenFaZTEN56ah5A+oKnM9n3G43u1An3ehMx21tqNLgSRC4veQIwbpr62rvbSloY0Dj+gLq5bonj12ysUQwFYbPjIUYZR9ZOyMzhFFDAncTeNaOd+D3RVZ4DAl+DMipoDVB0zPTu5ifExYXkGc1i0HSIPKxNkccQNWUYwK7GdRNKLcB3M/vDlXDEBNcKnAx4T4nJOJ/gUcoVJqgqvDEYBW+yTt/GKJm6ehqluyL/QVum6jN6squ+gAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vivit result adrenal\"\n        title=\"\"\n        src=\"/static/63dd5032616367f7f612e8b7ff317949/c1b63/vivit-result-adrenal.png\"\n        srcset=\"/static/63dd5032616367f7f612e8b7ff317949/5a46d/vivit-result-adrenal.png 300w,\n/static/63dd5032616367f7f612e8b7ff317949/0a47e/vivit-result-adrenal.png 600w,\n/static/63dd5032616367f7f612e8b7ff317949/c1b63/vivit-result-adrenal.png 1200w,\n/static/63dd5032616367f7f612e8b7ff317949/2a333/vivit-result-adrenal.png 1484w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Same hyperparameter, different results.</p>\n<p>반면 Adrenal MNIST 3D 데이터셋에서는 같은 learning rate에서도 Uniform Frame Sampling은 검증이 수렴하였으나 Tubelet Embedding은 발산하는 결과를 보였다. 따라서 두 토큰화 방법에 일괄적으로 학습이나 모델의 hyperparameter를 설정하여 결과를 비교하기 어렵다는 것을 알 수 있었다.</p>\n<p>이때 Uniform Frame Sampling은 일부 정보를 누락하거나 중복하기 때문에 학습 속도가 비교적 빠르지 않을까 생각할 수 있다. 즉 더 적은 정보를 학습한다면 학습 속도가 더 빠를 것이라는 가설을 세웠다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 24%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAABDElEQVR42j1QTcuCYBD0/1876aFTN3+AVpBCiKBhlqalFz+SPgwRrUQ05mUXXg/DDvvMM7O7wjiO+P1+GIYBbduiaRp8Pp+JE+iNNKQlvN9v7lP91xJIJwRBgOPxiPv9jqIo4Ps+sizDYrHAbDaDJEm4Xq9IkgT7/R55nsN1XaiqCtM0+e10OuF8PuP7/UIwDAOapiGOY4RhCF3XQSGHwwHL5RKWZaGqKjZbr9eIogi32w2O43DIarWCKIqYz+dI0xSCbdvYbrcsJCPiVKmvKApPQYae53HY5XLhj7vdjofYbDa8jSzLvKFAN3g8Hng+n5xMTapkUtf1dL+u61jzer1QluXE6TwE4n3f4w9jSWVSg1E7egAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vivit train time\"\n        title=\"\"\n        src=\"/static/3705b38520af67eab1c09b29ba6b8f22/c1b63/vivit-train-time.png\"\n        srcset=\"/static/3705b38520af67eab1c09b29ba6b8f22/5a46d/vivit-train-time.png 300w,\n/static/3705b38520af67eab1c09b29ba6b8f22/0a47e/vivit-train-time.png 600w,\n/static/3705b38520af67eab1c09b29ba6b8f22/c1b63/vivit-train-time.png 1200w,\n/static/3705b38520af67eab1c09b29ba6b8f22/ab40b/vivit-train-time.png 1736w\"\n        sizes=\"(max-width: 1200px) 100vw, 1200px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Training time comparison.</p>\n<p>그러나 데이터셋과 learning rate에 따라 임베딩 간의 학습 속도 차이는 크지 않았으며 여러 데이터셋과 learning rate에 대해 유의하지 않았다. 즉 두 임베딩에 따른 학습량의 차이는 크지 않은 것으로 보인다.</p>\n<br>\n<br>\n<h2>4. 결론</h2>\n<p>결론적으로 작은 규모의 비디오 데이터에 대한 학습과 검증 메트릭에서 일반적으로 Tubelet Embedding이 Uniform Frame Sampling보다 더 나은 결과를 보여주었다. 두 토큰화 방법 중 한쪽이 더 빠른 학습 속도를 보이지는 않았다. 그러나 AdrenalMNIST3D 데이터에 대한 결과가 나타내듯이, 두 임베딩 방법을 엄밀하게 같은 조건에서 비교할 수는 없었다. 또한 작은 규모의 3D 이미지에 대해 사전 학습 없이 작은 Transformer로 분석한 결과라는 점도 염두에 두어야 할 것이다.</p>\n<p>이 실험을 통해 실제 학습 결과를 분석하는 것이 흥미로운 한편, 엄밀한 의미에서 두개의 모델을 비교하는 것이 얼마나 어려운 일인지 알 수 있었다.</p>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .abyss { background-color: #000c18; }\n  .abyss .mtku {\n    text-decoration: underline;\n    text-underline-position: under;\n  }\n  .abyss .mtki { font-style: italic; }\n  .abyss .mtk15 { color: #9966B8; }\n  .abyss .mtk1 { color: #6688CC; }\n  .abyss .mtk5 { color: #FFEEBB; }\n  .abyss .mtk6 { color: #DDBB88; }\n  .abyss .mtk19 { color: #2277FF; }\n  .abyss .mtk7 { color: #225588; }\n  .abyss .mtk4 { color: #F280D0; }\n  .abyss .mtk11 { color: #22AA44; }\n  .abyss .mtk3 { color: #384887; }\n  .abyss .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));\n  }\n</style>","frontmatter":{"title":"[실험] ViViT의 토큰화 방법 비교하기","date":"February 21, 2023"}}},"pageContext":{"slug":"/AI/Vision/vivit-tokenizing/","previous":{"fields":{"slug":"/CS/DBMS/2022-12-31-dbms-mysql-join/"},"frontmatter":{"title":"[MySQL] JOIN"}},"next":{"fields":{"slug":"/AI/DL/2023-03-14-knowledge-distillation/"},"frontmatter":{"title":"[Paper] Knowledge Distillation, 2015"}}}},"staticQueryHashes":["1185972000","3231742164"],"slicesMap":{}}