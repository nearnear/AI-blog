{"componentChunkName":"component---src-pages-index-js","path":"/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"59bfe27f-7496-5217-963a-6ba982b1d607","excerpt":"이 글은 ChatGPT Prompt Engineering for Developers강의를 정리한 글입니다. 프롬프트 엔지니어링이란 LLM(거대 언어 모델) 또는 생성 모델에 사용자가 의도하는 결과를 도출하도록 지시사항을 전달하는 작업이다. 프롬프트 엔지니어링은 생성 모델의 결과를 구체화하는 데에 초점이 맞추어져 있다. 따라서 모델에게 프롬프트를 제공하는 것은 아직 모델이 AGI(Artificial General Intelligence)와는 멀다는 것을 의미하며, 앞으로의 모델은 프롬프트를 예측하는 방향으로 나아갈 것이라고 예상된다…","frontmatter":{"title":"ChatGPT 프롬프트 엔지니어링 가이드라인","subtitle":"[DeepLearning.AI, OpenAI] ChatGPT Prompt Engineering for Developers","draft":false,"date":"May 27, 2023"},"fields":{"slug":"/AI/NLP/chatgpt-prompt-engineering/"}}},{"node":{"id":"cc44e270-e5be-551c-a6af-ca421eccf9c0","excerpt":"실시간 뉴스 브리핑 한국어 서비스 기간 : 2023.05 ~ 진행중 주요 기능 : 1분 마다 네이버 뉴스의 분야별 주요 뉴스 스크레이핑 HuggingFace API를 통해 뉴스 기사 요약 사용 도구 : Help of ChatGPT on writing Javascript on Node.js HuggingFace Model API from Hub ainaize/kobart-news Netlify on deployment 프로젝트에 대해 계기 Why AI? ChatGPT의 이슈화로 AI 서비스에 대한 수요와 공급이 증가하고 있는데, 당…","frontmatter":{"title":"[진행중] briefing-now","subtitle":"💡 AI 기사 브리핑 웹 서비스","draft":false,"date":"May 22, 2023"},"fields":{"slug":"/+ Project/briefing-now/"}}},{"node":{"id":"586bf291-782c-50f5-ab2d-ed5dc9ad72fc","excerpt":"gatsby-remark-katex를 설치했다. 먼저, gatsby-remark-katex와 katex를 npm으로 다운받는다. 이제 gatsby-config.js 파일에 플러그인을 추가한다. 마지막으로 /src/templates/blog-post.js에 다음 코드를 추가한다. 이 경로는 Gatsby 폴더 구조에 따라 조금 다를 것이다. Gatsby의 플러그인 설치는 간단한 것이 장점이라고 느꼈다.","frontmatter":{"title":"[플러그인] Gatsby Katex 설치","subtitle":"gatsby-remark-katex","draft":false,"date":"May 21, 2023"},"fields":{"slug":"/Others/About Blog/gatsby-katex-plugin/"}}},{"node":{"id":"f761bca0-31aa-570f-90d2-0336c4cd983c","excerpt":"요약 : javascript string을 두번 디코딩하지 말자. 다음과 같은 warning이 발생하며 디코딩이 작동하지 않는다. 상황은 axios와 iconv로 스크레이핑을 하는 다음 코드에서 발생했다. response 버퍼에 저장된 값을 불러와 EUC-KR로 디코딩을 시도했다. Node.js v18.16.0 원인은 이중 디코딩 로그에서 주어진 링크로 들어가면 deprecation 원인이 설명되어 있다. 이미 저장된 string을 불러와 디코딩하는 경우, 처음 string 저장을 할 때 이미 JavaScript에서 utf-8으로…","frontmatter":{"title":"[iconv] decode()-ing 및 Buffer() deprecation","subtitle":"Iconv-lite warning: decode()-ing strings is deprecated.","draft":false,"date":"May 21, 2023"},"fields":{"slug":"/Others/JavaScript/buffer_deprecation/"}}},{"node":{"id":"571ce718-a855-5b25-80bb-82d132322ff2","excerpt":"0. Functions Functions added Latex 파싱 (gatsby-remark-kartex) 코드 syntax 스타일 (gatsby-remark-vscode) Functions to add Google 등 검색 노출 (SEO) 검색 기능 댓글 (utterances) 현재 위치한 category 표시 메인 화면에 메일 링크 추가 글 박스 만들기 북마크 템플릿 만들기 번역 1. Ground Gatsby-Clean-Blog-Starter 👏🏼 Quick Start More Mardown Header example Lore…","frontmatter":{"title":"[Gatsby] Gatsby 블로그","subtitle":"🏕 Blog","draft":false,"date":"May 21, 2023"},"fields":{"slug":"/Others/About Blog/gatsby-blog/"}}},{"node":{"id":"4d2fa353-1336-541a-8fac-5e60877fa43b","excerpt":"한국어 토큰화(또는 형태소 분석)를 파이썬 패키지 KoNLPy를 이용하여 수행해보자. 0. 왜 필요한가? 한국어는 토크나이징이 어려운 언어이다. 한국어는 영어와 달리 명사와 조사를 띄어쓰지 않는다. 한국어는 어순이 아니라 조사 또는 조사의 유무에 따라 문법적 기능이 정해진다. 한국어는 띄어쓰기 규칙이 모호하다. 한국어는 주어를 생략할 수 있고, 평서문과 의문문에 문법적 차이가 없다. ex. '집에 갔어.', '집에 갔어?' 따라서 최소의 의미 단위인 형태소를 분석하는 도구(Morphological Analyzer)가 필요하다. 형…","frontmatter":{"title":"[KR] KoNLPy로 한국어 토큰화하기","subtitle":"한국어 처리 통합 패키지 KoNLPy를 알아보자.","draft":false,"date":"September 27, 2022"},"fields":{"slug":"/AI/NLP/konlpy/"}}},{"node":{"id":"31565a44-d146-5c32-afd0-6af3e932d837","excerpt":"Paper : Siamese Neural Networks for One-shot Image Recognition 요약 샴 신경망은 입력 데이터 쌍의 유사도를 비교하는 신경망을 학습한 뒤, 분산을 알 수 없는 새로운 샘플을 각 클래스에서 추출한 단 하나의 샘플과 비교해서 분류 작업을 수행한다. 샴 신경망은 이러한 one-shot learning에 획기적인 성과를 도출했다. 목표 : 주어진 데이터를 학습해 재학습 없이 정보가 적은 클래스에 대한 예측력을 높이고 싶다.\n{: .notice} one-shot learning ?\n각 클래스…","frontmatter":{"title":"[Paper] Siamese Neural Network, 2015","subtitle":"다양한 modality에서 활용되는 one-shot 분류 네트워크","draft":false,"date":"August 22, 2022"},"fields":{"slug":"/AI/NLP/siamese-nn/"}}},{"node":{"id":"0db6b306-7fbb-5e1e-abb2-13d941036ef4","excerpt":"Paper: Vaswani et al., 2017, \"Attention is all you need\" (Link to arxiv) 0. Transformer 트랜스포머는 Seq2Seq 모델과 비슷한 인코더-디코더 구조를 갖고 있지만, 보다 긴 시퀀스를 효율적으로 다룰수 있는 모델로 환영받았다. 트랜스포머는 새로운 어텐션을 도입했다. 2014년에 등장한 어텐션(Bahdanau et al., 2014)이 RNN 네트워크의 성능을 향상시키는 활용된 것과 달리, 2017년의 어텐션은 신경망을 이용하지 않고 행렬 곱으로 이루어진 방식을 제…","frontmatter":{"title":"[Paper/Trax] Transformer, 2017","subtitle":"Trax 라이브러리 코드로 Transformer를 이해해보자.","draft":false,"date":"April 14, 2022"},"fields":{"slug":"/AI/NLP/transformer/"}}},{"node":{"id":"48b9d13f-36fb-5de4-b46a-1a9923b8ae90","excerpt":"이 글은 deeplearning.ai의 NLP Specialization를 참고하여 나이브 베이즈 모델을 텍스트 정서 분석에 초점을 맞춰 정리한 글입니다. Github에서 Naive Bayes 코드 보기 0. 모델 개략 나이브 베이즈 모델은 분류 과제를 위한 확률 모델이다. 훈련 데이터에 등장하는 모든 단어의 빈도를 세어서 각 데이터에 대한 조건부 확률의 비율을 계산하므로 분류 과제를 수행하는데 적합하다. 나이브 베이즈 모델은 훈련과 예측을 빠르게 수행할 수 있으므로 baseline 모델로 적합하다. 문장에 있는 각 단어들이 독립…","frontmatter":{"title":"텍스트 나이브 베이즈 분류","subtitle":"DL 이전의 텍스트 처리기인 나이브 베이즈 분류를 알아보자.","draft":false,"date":"April 13, 2022"},"fields":{"slug":"/AI/NLP/naive-bayes/"}}},{"node":{"id":"a78d5036-beb0-5e6f-918c-05187421f263","excerpt":"word2vec은 2013년 구글에서 고안한 자연어 처리 아이디어로, 이에 기반한 모델은 Continuous Bag-of-Words(CBOW)와 Skip-gram 두가지가 있다. 이 글은 그 중에서 CBOW 모델을 원 논문과 deeplearning.ai 수업을 참고하여 정리한 글이다. 원 논문: Mikolov et. al., 2013, Efficient Estimation of Word Representations in Vector Space (arxiv) Mikolov et. al., 2013, Distributed Repres…","frontmatter":{"title":"Word2Vec - CBOW","subtitle":"","draft":false,"date":"March 31, 2022"},"fields":{"slug":"/AI/NLP/word2vec-cbow/"}}}]}},"pageContext":{}},"staticQueryHashes":["1185972000","3004417078","3231742164"],"slicesMap":{}}