---
title: "Knowledge Distillation, 2015"
categories: Papers
tags:
    - transfer learning
---


ì§€ì‹ ì¦ë¥˜(Knowledge Distillation)ëŠ” í•™ìŠµëœ í¬ê¸°ê°€ í° ëª¨ë¸(ë“¤)ì˜ ì •ë³´ë¥¼ ìµœëŒ€í•œ ë³´ì¡´í•˜ë©´ì„œ í¬ê¸°ëŠ” ì‘ì€ ëª¨ë¸ë¡œ ì˜®ê¸°ëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê³  ìˆë‹¤. ë”°ë¼ì„œ ëª¨ë¸ í•™ìŠµì„ ë§ˆì¹œ í›„ ë°°í¬í•˜ëŠ” ê³¼ì • ë“± ì—°ì‚° ì œì•½ì´ ìˆëŠ” ê²½ìš° ê³ ë ¤í•´ ë³¼ ìˆ˜ ìˆëŠ” ê¸°ìˆ ì´ë‹¤. 
{: .notice--info}

> Paper : [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)


## 1. ì§€ì‹ ì¦ë¥˜

### 1.1 ê°œìš”

ì§€ì‹ ì¦ë¥˜ëŠ” ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” í°(cumbersome) ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ê°€ í•™ìŠµí•œ soft targetì„ í™œìš©í•´ ê·œëª¨ê°€ ì‘ì€(small) ëª¨ë¸ì— íš¨ê³¼ì ìœ¼ë¡œ transfer learningì„ í•˜ëŠ” ë°©ë²•ì´ë‹¤. ì´ë•Œ hard targetì´ë€  ë˜ëŠ” 1ë¡œ í‘œí˜„ë˜ëŠ” ë°ì´í„° ìƒ˜í”Œì˜ true labelì„, soft targetì´ë€ softmax í•¨ìˆ˜ì˜ ê²°ê³¼ í™•ë¥  ë˜ëŠ” ë¡œì§“ì„ ì˜ë¯¸í•œë‹¤. Soft targetì€ ê·¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ ë§ì€ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë¯€ë¡œ, ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•œ ê°’ì´ ì˜ë¯¸ë¥¼ ê°€ì§„ë‹¤. ì´ëŸ° ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë” ì‘ì€ ëª¨ë¸ë¡œ ì´ì „í•˜ëŠ” ê²ƒì´ ì§€ì‹ ì¦ë¥˜ì˜ ëª©ì ì´ë‹¤. 


#### ë¬¸ì œ: soft target í™•ë¥ ì´ ì‘ì•„ cross-entopyì— ë°˜ì˜ë˜ì§€ ì•ŠëŠ”ë‹¤.
ì‹¤ì œë¡œëŠ” soft targetì— ëŒ€í•œ ì—¬ëŸ¬ í´ë˜ìŠ¤ì˜ softmax í™•ë¥  ê°’ì´ ë§¤ìš° ì‘ê¸° ë•Œë¬¸ì—, cross-entropy ë¹„ìš© í•¨ìˆ˜ì— íš¨ê³¼ì ìœ¼ë¡œ ì´ ì •ë³´ë¥¼ ì…ë ¥í•˜ê¸° ì–´ë µë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´ MNIST í•™ìŠµì²˜ëŸ¼ ì¶©ë¶„íˆ í° ëª¨ë¸ì´ ë†’ì€ ì •í™•ë„ë¥¼ ë‚´ëŠ” ê³¼ì œì—ì„œ í•™ìŠµëœ ì •ë³´ëŠ” ëŒ€ë¶€ë¶„ soft targetì— ì €ì¥ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´ "2"ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„°ëŠ” "3"ìœ¼ë¡œ ë¶„ë¥˜ë  í™•ë¥ ì´ $10^{-6}$ì¸ë° ë°˜í•´ "7"ë¡œ ë¶„ë¥˜ë  í™•ë¥ ì€ $10^{-9}$ì¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° ë°ì´í„°ì— ëŒ€í•œ í™•ë¥  ë¹„ìœ¨ì€ í´ë˜ìŠ¤ ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê·€ì¤‘í•œ ì •ë³´ì´ì§€ë§Œ í™•ë¥  ìì²´ì˜ ê°’ì´ ë„ˆë¬´ ì‘ì•„ cross-entropy ë¹„ìš© í•¨ìˆ˜ì—ì„œëŠ” ê±°ì˜ ë°˜ì˜ë˜ì§€ ì•ŠëŠ”ë‹¤.

**ëª¨ë¸ í•™ìŠµì‹œ ì°¸ê³ :** soft targetì´ ì¶©ë¶„íˆ ì—”íŠ¸ë¡œí”¼ê°€ ë†’ìœ¼ë©´, hard targetì— ë¹„í•´ ë” ë§ì€ ì •ë³´ë¥¼ ë‹´ê³  ìˆìœ¼ë©°, í•™ìŠµì‹œ ê·¸ë˜ë””ì–¸íŠ¸ì˜ variance ë˜í•œ ì‘ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë”°ë¼ì„œ ê°€ë²¼ìš´ ëª¨ë¸ì€ ë” ì‘ì€ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë” í° learning rateë¥¼ ì‚¬ìš©í•´ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.
{: .notice}

#### í•´ê²°: softmax í•¨ìˆ˜ì˜ temperatureë¥¼ ë†’ì¸ë‹¤.
ì§€ì‹ ì¦ë¥˜ëŠ” ì´ ë¬¸ì œë¥¼ softmax í•¨ìˆ˜ì˜ ì˜¨ë„(temperature)ë¥¼ ë†’ì—¬ì„œ í•´ê²°í•œë‹¤. ì—¬ê¸°ì„œ ì˜¨ë„ë€ softmax í•¨ìˆ˜ì˜ ë³€ìˆ˜ë¡œ, ì˜¨ë„ë¥¼ ë†’ì¼ìˆ˜ë¡ í•¨ìˆ˜ëŠ” ë” ëœë¤í•œ ê²°ê³¼ë¥¼ ë„ì¶œí•´ í´ë˜ìŠ¤ í™•ë¥  ë¶„í¬ë¥¼ ì¤„ì¸ë‹¤. ë†’ì€ ì˜¨ë„ë¥¼ í†µí•´ ë” "ë¶€ë“œëŸ¬ìš´(soft)" í´ë˜ìŠ¤ í™•ë¥  ë¶„í¬ë¥¼ ì–»ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê²°ë¡ ì ìœ¼ë¡œ soft targetë“¤ì˜ í™•ë¥ ì„ ì „ë°˜ì ìœ¼ë¡œ ë†’ì¼ ìˆ˜ ìˆë‹¤. 

ìš°ì„  ë¬´ê±°ìš´ ëª¨ë¸ì´ ì¶©ë¶„íˆ "soft"í•œ target setì„ ë„ì¶œí•  ë•Œê¹Œì§€ temperatureë¥¼ ë†’ì—¬, ì´ ë†’ì€ temperatureë¥¼ ê°€ë²¼ìš´ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ì ìš©í•˜ì—¬ ê³„ì‚°í•œë‹¤. ì´ë•Œ ì¦ë¥˜ëœ ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” 1ï¸âƒ£ transfer setì— ë¼ë²¨ì´ ì—†ëŠ” ê²½ìš°, í° ëª¨ë¸ì˜ soft targetê³¼ ë†’ì€ ì˜¨ë„ë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµí•œë‹¤. 2ï¸âƒ£ transfer setì˜ ë¼ë²¨ì„ ì–»ì„ ìˆ˜ ìˆëŠ” ê²½ìš°, ì•ì„  í•™ìŠµê³¼ correct targetì„ 1ì˜ ì˜¨ë„ë¡œ í•™ìŠµí•œ cross-entropy í•¨ìˆ˜ì˜ ê°€ì¤‘ì¹˜ í‰ê· ì„ í™œìš©í•˜ì—¬ í•™ìŠµí•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ë‹¤. 

temperature $T$ë¥¼ í¬í•¨í•œ softmaxëŠ” ë¡œì§“ $z_i$ë¥¼ ë‹¤ë¥¸ ë¡œì§“ë“¤ ${z_i}$ì™€ ë¹„êµí•˜ì—¬ í™•ë¥  $q_i$ë¥¼ ë„ì¶œí•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.

$$
q_i = \frac{exp(z_i / T)}{\sum_j exp(z_j/ T)}
$$

$T=1$ì¸ ê²½ìš°ëŠ” ì¼ë°˜ì ì¸ softmax í•¨ìˆ˜ê°€ ë˜ë©°, $T$ë¥¼ ë†’ì´ë©´ ë” "soft"í•œ í´ë˜ìŠ¤ í™•ë¥  ë¶„í¬ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

2ï¸âƒ£ ì˜ ê²½ìš°ì— ëŒ€í•œ ìµœì¢… ì†ì‹¤ í•¨ìˆ˜ëŠ” ê°€ì¤‘ì§€ $\alpha$ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤ ($T^2$ë¥¼ ìŠ¤ì¼€ì¼ë§ í•´ì£¼ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë•Œë¬¸ì¸ë°, ìì„¸íˆëŠ” ì•„ë˜ì—ì„œ ì‚´í´ë³¸ë‹¤):

$$
L = \alpha T^2 \text{CE} (P_{small}^{T=t}, P_{big}^{T=t}) + (1- \alpha) \text{CE}(P_{small}^{T=1}, \text{true label})
$$



#### transfer set í™œìš©ë°©ë²•
transfer setì˜ ë°ì´í„°ì— ëŒ€í•´ ë¬´ê±°ìš´ ëª¨ë¸ì˜ soft target ë¶„í¬ë¥¼ í™œìš©í•˜ë©´ distilationì„ í•  ìˆ˜ ìˆë‹¤. ë§Œì•½ transfer setì´ ë¼ë²¨ëœ ê²½ìš°, soft targetê³¼ hard targetì— ëŒ€í•œ cross-entropyë¥¼ ê°ê° ê³„ì‚°í•˜ì—¬ ê°€ì¤‘í•© í•  ìˆ˜ ìˆë‹¤. 
1. soft targetì˜ cross-entropyë¥¼ ì˜¤ë¦¬ì§€ë„ ëª¨ë¸ì˜ temperatureë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°í•œë‹¤.
2. hard targetì˜ cross-entorpyë¥¼ $T=1$ë¡œ ê³„ì‚°í•œë‹¤.

ì´ë•Œ soft targetìœ¼ë¡œ ìƒì„±í•œ ê·¸ë˜ë””ì–¸íŠ¸ì˜ í¬ê¸°ëŠ” $1/T^2$ë°° ìŠ¤ì¼€ì¼ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ì— ìµœì¢…ì ìœ¼ë¡œ $T^2$ë¥¼ ê³±í•´ì•¼ $T$ë¥¼ ë³€í™”í•´ë„ hardì™€ soft targetì˜ ë¹„ìœ¨ì„ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.



#### ğŸ‰ ì˜ì‚¬ ì½”ë“œ

ìœ„ì—ì„œ ì •ì˜í•œ softmax í•¨ìˆ˜ì™€ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ëµí•œ ì˜ì‚¬ ì½”ë“œë¥¼ ì“¸ ìˆ˜ ìˆë‹¤.

```python
# Define distilled model which has softmax layer with temperature as final layer.
class DistilledModel(Module):
    def __init__(self, input_dim, output_dim, temp=1, name=None):
        super().__init__(name=name)
        self.small_model = ... # define some small model.
        self.temp = temp
        
    def softmax_temp(self, x):
        exp_x = np.exp(x / self.temp)
        exp_x = exp_x - np.max(exp_x)
        sum_exp_x = np.sum(exp_x)
        return exp_x / sum_exp_x

    def __call__(self, x):
        logit = self.small_model(x) 
        output = self.softmax_temp(logit)
        return output
        
# Define final weighted cross-entropy function for distilled model.
# By the paper, it is recommended alpha > 0.5.
def final_cross_entropy(y_true, y_pred, y_soft, big_soft, alpha, high_temp):
    entropy_1 = CrossEntropy(y_soft, big_soft)
    entropy_2 = CrossEntropy(y_true, y_pred)
    return alpha * (high_temp ** 2) * entropy_1 + (1. - alpha) * entropy_2

# Train small model with soft target and high temperature from the cumbersome model.
distilled_model_1 = DistilledModel(input_dim, output_dim, temp=high_temp)
distilled_model_1.compile(...)
y_soft = distilled_model_1.fit((transfer_set, soft_target))

# Train true target of transfer set with temperature 1.
distilled_model_2 = DistilledModel(input_dim, output_dim)
distilled_model_2.compile(...)
y_pred = distilled_model_2.fit((transfer_set, true_target))

# Compute final cross-entropy function.
final_cross_entropy = final_cross_entropy(y_true, y_pred, 
                                          y_soft, big_soft,
                                          alpha, high_temp)
```


### 1.2 ì§€ì‹ ì¦ë¥˜ íŠ¹ìˆ˜ ì‚¬ë¡€ : Logit í™œìš©

ì‹¤ì œë¡œëŠ” Logitì„ í™œìš©í•˜ì—¬ cross-entropy í•¨ìˆ˜ë¥¼ ë³€í™˜í•˜ëŠ” ê²ƒ ë˜í•œ ì§€ì‹ ì¦ë¥˜ì˜ í•œ ì‚¬ë¡€ë‹¤. ì´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ë¡œì§“ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ë””ì„¼íŠ¸ë¥¼ í•´ë³´ì.

- í° ëª¨ë¸ì˜ ë¡œì§“ $v_i$, í™•ë¥  $p_i$
- ì¦ë¥˜ëœ ëª¨ë¸ì˜ ë¡œì§“ $z_i$, í™•ë¥  $q_i$
- ì¦ë¥˜ëœ ëª¨ë¸ì˜ cross-entopy $C$

ì´ë•Œ ì¦ë¥˜ëœ ëª¨ë¸ì˜ cross-entropy ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤(ì—¬ê¸°ì„œëŠ” í•˜ë‚˜ì˜ ë¡œì§“ì— ëŒ€í•œ í¸ë¯¸ë¶„ìœ¼ë¡œ ë‚˜íƒ€ëƒˆë‹¤):

$$
\begin{aligned}
\frac{\partial C}{\partial z_i} 
&= \frac{1}{T} ( q_i - p_i) \\
&= \frac{1}{T} (\frac{e^{z_i/T}}{\sum_j e^{z_j/T}} - \frac{e^{v_i/T}}{\sum_j e^{v_j/T}})
\end{aligned}
$$

ì—¬ê¸°ì„œ 1ï¸âƒ£ ì˜¨ë„ê°€ ë¡œì§“ì˜ ê°’ë³´ë‹¤ ìƒëŒ€ì ìœ¼ë¡œ í¬ë©´ (ì¦‰ $1/T$ê°€ ì „ì²´ê°’ì„ ì¶©ë¶„íˆ ì‘ê²Œ ë§Œë“¤ë©´) Smoothingì„ ì ìš©í•  ìˆ˜ ìˆë‹¤:

$$
\frac{\partial C}{\partial z_i} 
\approx 
\frac{1}{NT} (\frac{1 + e^{z_i/T}}{N + \sum_j e^{z_j/T}} - \frac{1 + e^{v_i/T}}{N + \sum_j e^{v_j/T}})
$$

ë˜í•œ 2ï¸âƒ£ ê°€ì •ì„ í†µí•´ ë‘ ë¡œì§“ì˜ í‰ê· ì´ $0$ì´ ë˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆë‹¤ (ì¦‰ $\sum_j z_j = \sum_j v_j = 0 $). ìœ„ì˜ ë‘ê°€ì§€ ì¡°ê±´ì´ ë§Œì¡±ë˜ë©´ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ **ë‘ ë¡œì§“ì˜ ì˜¤ì°¨ì— ëŒ€í•œ ìƒìˆ˜ë°°**ê°’ìœ¼ë¡œ ê·¼ì‚¬í•  ìˆ˜ ìˆë‹¤:

$$
\frac{\partial C}{\partial z_i} 
\approx 
\frac{1}{NT^2} (z_i - v_i)
$$

ìœ„ì˜ í¸ë¯¸ë¶„ì„ ëª¨ë“  ë¡œì§“ $z_i$ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ êµ¬í•˜ê³  $T^2$ë¡œ ìŠ¤ì¼€ì¼ë§ì„ í•˜ë©´, ì§€ì‹ ì¦ë¥˜ëŠ” ë‘ ë¡œì§“ì˜ ì˜¤ì°¨ ì œê³± $\frac{1}{2} (z_i - q_i)^2$ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì‘ì—…ì´ ëœë‹¤.


## ì‹¤í—˜

### 2.1 ê¸°ë³¸ ì‹¤í—˜: MNIST 

distillationìœ¼ë¡œ í° ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆëŠ”ì§€ ì‹¤í—˜í–ˆë‹¤.

| size of NN | generalization | test errors |
| :---: | :---: | :---: |
| big | Dropout | 67 |
| small | None | 146 |
| small | Distillation | 74 |

ëª¨ë¸ì€ ëª¨ë‘ 2ê°œì˜ hidden layerë¥¼ ê°€ì§€ë©° í° ëª¨ë¸ì˜ ê²½ìš° 1200ê°œ, ì‘ì€ ëª¨ë¸ì˜ ê²½ìš° 800ê°œì˜ hidden unitì„ ê°€ì§„ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ MNISTì˜ 6ë§Œê°œ ë°ì´í„°ì…‹ì— ëŒ€í•´ í•™ìŠµí•œ í° ëª¨ë¸ê³¼ ê·¸ soft targetì„ ì¶”ê°€ì ìœ¼ë¡œ í•™ìŠµí•œ ì‘ì€ ëª¨ë¸ì€ ì„±ëŠ¥ì´ ë¹„ìŠ·í–ˆë‹¤. ì¶©ë¶„í•œ bias(3.5)ë¥¼ ê³ ë ¤í•˜ë©´ ì‘ì€ ëª¨ë¸ì˜ í•™ìŠµ ë°ì´í„°ì—ì„œ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ê°€ ëˆ„ë½ë˜ë”ë¼ë„ distillationì„ í†µí•´ ëˆ„ë½ëœ í´ë˜ìŠ¤ì— ëŒ€í•´ 98.6%ì˜ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆë‹¤. ë‘ê°œì˜ í´ë˜ìŠ¤ê°€ ëˆ„ë½ëœ ê²½ìš° biasë¥¼ ë” ë†’ì—¬(7~8) ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆì—ˆë‹¤.

### 2.2 ì•™ìƒë¸” íš¨ê³¼ ì‹¤í—˜: speech recognition

ì•™ìƒë¸” ëª¨ë¸ì„ distillingí•˜ëŠ” ê²ƒì´ ê°™ì€ í¬ê¸°ì˜ ë‹¨ìˆœ ëª¨ë¸ì— ë¹„í•´ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•˜ê³ ì í–ˆë‹¤.

ë…¼ë¬¸ì´ ì“°ì¼ ë‹¹ì‹œì˜ ìë™ ìŒì„± ì¸ì‹ì€ DNNì„ í†µí•´ ë§¤ ì‹œì ì— waveformì„ ë…ë¦½ Hidden Markov ëª¨ë¸(HMM)ì˜ íŠ¹ì • ìƒíƒœì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ì˜ˆì¸¡í–ˆìœ¼ë©°, ë¼ë²¨ì€ ì‹œí€€ìŠ¤ ìˆœì„œë¡œ ê°•ì œë˜ì—ˆë‹¤. ì¦‰ ì¼ë°˜ì ìœ¼ë¡œ DNNì„ í†µí•´ ì˜ˆì¸¡ê°’ê³¼ ë¼ë²¨ì˜ frameë‹¹ í´ë˜ìŠ¤ë¥¼ cross entropy ìµœì†Œí™” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí–ˆìœ¼ë¯€ë¡œ distillationì„ ìˆ˜í–‰í•˜ê¸° ì í•©í–ˆë‹¤. 

ì‹œê°„ tì—ì„œ acoustic ë°ì´í„° $s_t$ë¥¼ HMMì˜ "ì˜³ì€"(hard target) ìƒíƒœ í™•ë¥  $h_t$ë¡œ ë‚˜íƒ€ë‚´ëŠ” í™•ë¥ ë¡œ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° $\theta$ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê²°ì •í•  ìˆ˜ ìˆë‹¤:

$$
\theta = \text{argmax}_{\theta'}P(h_t|s_t;\theta')
$$

| System | Test Frame Accuracy | WER |
| :---: | :---: | :---: |
| Baseline | 58.9% | 10.9% |
| 10xEnsemble | 61.1% | 10.7% |
| Distilled Single Model | 60.8% | 10.7% |

Baselineì€ Android voice searchì´ë©° ì•™ìƒë¸”ì€ 10ê°œì˜ ëª¨ë¸ì— ëŒ€í•´ ì§„í–‰í•˜ì˜€ë‹¤. ì˜ë„í•œëŒ€ë¡œ ì•™ìƒë¸” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì „ì´ë˜ì—ˆìŒì„ Accuracyì™€ WERì˜ ìœ ì‚¬í•¨ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

### 2.3 Regularizer íš¨ê³¼ ì‹¤í—˜

Soft targetì„ hard targetê³¼ ê°™ì´ í™œìš©í•˜ëŠ” ê²ƒì´ regularizer ì—­í• ì„ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì¸ë‹¤. 

| System & training set | Train Frame Accuracy | Test Frame Accuracy |
| :---: | :---: | :---: |
| Baseline(100% of training set) | 63.4% | 58.9% |
| Baseline(3% of training set) | 67.3% | 44.5% |
| Soft Targets(3% of training set) | 65.4% | 57.0% |

ì•ì„œ ë³¸ speech recognitionê³¼ì œì˜ baselineì€ 85Mê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì¡Œë‹¤. í•™ìŠµ ë°ì´í„°ì˜ 3% ë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ëª¨ë¸ì„ í•™ìŠµí•˜ë©´ ì‹¬í•œ overfittingì´ ë‚˜íƒ€ë‚¬ì§€ë§Œ, soft targetì„ í™œìš©í•˜ì—¬ í•™ìŠµí•˜ë©´ ì „ì²´ ë°ì´í„°ì…‹ì˜ ëŒ€ë¶€ë¶„ì˜ ì •ë³´ë¥¼ í•™ìŠµí•  ë¿ë§Œ ì•„ë‹ˆë¼ early stopping ì—†ì´ë„ ìˆ˜ë ´í•˜ëŠ” ê²°ê³¼ë¥¼ ë³´ì˜€ë‹¤.



