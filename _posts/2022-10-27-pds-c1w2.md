---
title: "[PDS]C1W2 - 데이터 Bias & FI 분석"
categories: 
    - AWS
    - ML/DL
tags:
    - aws
    - data processing
header: 
    image: /imgs/post-imgs/aws-specialization-header.png
---

<figure>
	<a href="/imgs/post-imgs/machine_learning_workflow_c1w2.png"><img src="/imgs/post-imgs/machine_learning_workflow_c1w2.png"></a>
	<figcaption>This week's topic.</figcaption>
</figure>

모델을 학습하기 위한 데이터 피쳐 분석 방법을 알아본다.


## 1. Statistical Bias

**통계적 편향(Statistical Bias)**이란 파라미터를 과대 추정(overestimate)하거나 과소 추정(underestimate)하는 통계적 경향이다. 학습 데이터가 편향되었다는 것은 문제 공간(problem space)를 포괄적으로 대표하지 못하는 상태를 일컫는다. 즉 데이터셋의 특정 요소가 모델의 학습에 대해 가중치가 크게 매겨져 있는 것으로, 예를 들어 제품 리뷰 데이터셋의 양이 카테고리 별로 차이가 나거나, 카테고리 별로 타겟 값이 불균형한 경우가 해당된다.(자세한 경우에 대해서는 Measure Pretraining Bias에서 다룬다.)

### 1.1. 편향의 요인들
머신러닝 모델이나 데이터셋에 편향이 발생하는 요인은 다양하다.

1. *Activity Bias* : 특정 서비스를 이용하는 사람들이 전체 인구 집단을 대표한다고 할 수 없다. 예를 들어 social media platform의 데이터가 충분히 많은 사람을 대표한다고 생각하기 쉽지만, 실제로는 지구의 인구 집단에서 소수만이 특정 플랫폼을 이용하므로 그 데이터는 지구의 인구 집단을 공평하게 반영하지 못한다.
2. *Societal Bias* : 사회의 체계와 관습에서 받아들여지는 의식적이고 무의식적인 사회적 편향을 의미한다. 사람이 생성한 컨텐츠는 이런 사회적 편향을 벗어나기 힘들다.
3. *Selection Bias* : 머신러닝 시스템 자체에서 발생하는 편향을 의미한다. 예를 들어 추천 시스템에서 추천된 컨텐츠가 먼저 노출되는 경우를 생각해보자. 사용자가 과거에 선택했던 컨텐츠에 기반하여 추천된 컨텐츠 범위 내에서 컨텐츠 선택이 일어난다면 이는 Feedback loop가 일어나며, 이는 추천 시스템 자체가 생성하는 편향이다.
4. *Data Drift* (또는 *Data Shift*) : 학습 데이터에 편향이 없더라도 학습이 끝난 뒤의 모델에 편향이 나타날 수 있다. Data Drift는 주로 학습 데이터의 분포와 테스트 데이터의 분포가 다를 때 나타나는 편향이다. Convariant drift는 데이터셋의 독립 변수 분포나 피쳐 분포가 변화하는 경우를 가리킨다. 반면 라벨이나 타겟 값이 바뀐 경우는 Prior probability drift라고 한다. 또는 피쳐와 타겟 값의 관계가 변화하는 경우는 Concept drift라고 한다. 

예를 들어 지리적이고 시간적인 요인에 의해 같은 분류 클래스를 다른 이름으로 부르는 경우도 있고, 특정 피쳐에 의해서 라벨의 정의가 변화하는 경우도 있다. 이는 모두 drift에 해당한다. 그러므로 학습의 전후에 지속적으로 데이터셋에 이런 편향이 없는지 검토하는 것이 모델의 상업적 측면과 모델에 대한 규제 측면에서 모두 중요하다.

### 1.2. 편향의 Metric

**Notation:** **facet**이란 분석의 대상이 되는 민감한(sensitive) 피쳐를 의미한다. 편향의 metric은 전체 데이터가 아닌 특정 facet에 대해 작용함에 유의하자.
{: .notice--info}

어떤 피쳐에 대해서 어떤 편향을 분석하는지 결정해야 한다. 

- [*Class Imbalance (CI)*](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-bias-metric-class-imbalance.html) : 서로 다른 facet 값에 대해 그 수의 비대칭을 측정한다. 예를 들어, 상품 리뷰 데이터에서 특정 카테고리의 리뷰 수가 다른 카테고리의 리뷰 수보다 특히 많거나 적은지 조사한다.
- [*Difference in Proportions of Labels (DPL)*](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-data-bias-metric-true-label-imbalance.html) : 서로 다른 facet 값에 대해 긍정적인 결과값의 비대칭을 측정한다. 예를 들어, 상품 리뷰 데이터에서 특정 카테고리의 별점이 다른 카테고리의 별점보다 특히 높지는 않은지 조사한다. 
- [*Kullback-Leibler Divergence (KL)*](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-data-bias-metric-kl-divergence.html) : 서로 다른 facet 값에 대해 라벨의 분포를 비교하여 그 차이(divergence)를 점수로 매긴다. 예를 들어, 상품 리뷰 데이터에서 특정 카테고리의 별점 분포가 다른 카테고리의 별점 분포와 얼마나 차이가 나는지 조사한다. KL은 facet 사이의 상대적 엔트로피로도 알려져 있으며 고정된 라벨에 대한 facet A의 분포에서 facet B의 분포로 이동할 때 손실되는 정보의 양으로 해석할 수 있다. 
- [*Lp-norm (LP)*](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-data-bias-metric-lp-norm.html) : 서로 다른 facet 값에 대해 라벨의 분포 사이의 p-norm 거리를 측정한 값이다. 예를 들어, 상품 리뷰 데이터에서 facet A와 B의 별점 {1, 2, 3, 4, 5}에 대한 유클리디안 거리(p=2)를 계산한다.

이 metric들은 [Measure Pretraining Bias](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html)로, Clarify로 분석할 때 `clarify_processor.run_pre_training_bias`의 파라미터 `methods`에 리스트로 전달할 수 있다.

### 1.3. Amazon SageMaker Data Wrangler로 편향 측정하기

**통계적 편향을 분석하는 두가지 방법:** AWS Toolkit에서 통계적 편향을 분석하는데에 두가지 방법이 있다. 
Amazon SageMaker Data Wrangler는 UI에 기반한 시각적 분석을 제공한다. Data Wrangler는 데이터의 부분 집합에 대한 분석을 간단한 방식으로 제공한다. 여러개의 데이터에서 시각적 탐색을 진행하거나 간단한 편향 분석을 진행하는 경우에 선택한다.  
이에 반해, Amazon SageMaker Clarify는 API 접근과 scaling에 초점을 두고있다. Processing jobs라는 construct로 대규모 편향 분석을 분산 클러스터를 조절할 수 있다. 전체 데이터셋에 대해 분석을 진행하므로 스케일이 큰 데이터셋에 대해 클라우드 자원을 사용하는 경우 선택할 수 있다.
{: .notice--info}

Data Wrangler를 이용해 데이터의 편향을 분석하는 방법은 간단하다.  

...UI...

### 1.4. Amazon SageMaker Clarify로 편향 측정하기
Clarify는 학습 데이터 뿐만 아니라 학습 모델과 배포된 모델에 대한 편향 탐색(bias detection)을 수행한다. 또한 데이터와 모델의 설명가능성(explainability)와 drift를 측정할 수 있다.

#### API for Statistical Bias Report 
분석 실행에 앞서 세가지 객체를 정의한다. 

```python
from sagemaker import clarify

# 1. SageMakerClarifyProcessor를 정의한다.
clarify_processor = clarify.SageMakerClarifyProcessor(
    role=role,
    instance_count = 1,
    instance_type='ml.c5.2xlarge',
    sagemaker_session=sess)

# 2. Clarify 라이브러리에 data config 객체를 설정한다.
bias_data_config = clarify.DataConfig(
    s3_data_input_path=...,
    s3_output_path=...,
    label='label_name',
    headers=df_balanced.columns.to_list(),
    dataset_type='text/csv')

# 3. Clarify 라이브러리에 bias config 객체를 설정한다.
bias_config = clarify.BiasConfig(
    label_values_or_threshold=[...],
    facet_name='product_category')
```
- SageMaker Clarify Processor는 분석을 위해 분산 클러스터의 스케일을 설정하는 construct이다. `instance_count`와 `instance_type` 파라미터를 통해 각각 클러스터에 포함된 노드의 개수와 각 노드의 연산 능력(capacity)를 설정한다. 전체 연산 능력은 노드의 연산 능력과 메모리, 네트워크 속도로 결정된다. 
- Clarify가 활용하는 SafeMaker Processing Job은 데이터가 S3에 있는 것을 가정하므로, Data Config를 통해 입력 데이터셋이 저장된 S3 경로와 분석 리포트가 저장될 S3 경로를 설정한다.
- Bias Config 객체는 `label_values_or_threshold`에 원하는 라벨 값을 전달하며, `facet_name`에는 편향을 측정하고자하는 피쳐의 이름을 전달한다.

정의한 객체를 파라미터로 Clarify processor에서 모델 학습전 편향 분석을 실행한다.

```python
# Pre training bias job을 실행한다.
clarify_processor.run_pre_training_bias(
    data_config=bias_data_config,
    data_bias_config=bias_config,
    methods=["CI", "DPL", ...],
    wait=<<False/True>>,
    logs=<<False/True>>)
```
- `methods`로 [Measure Pretraining Bias](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html)를 전달하며, `wait` 파라미터는 분석을 background에서 실행하는 여부를 전달한다.

#### Background Processing

<figure>
	<a href="/imgs/post-imgs/amazon_sagemaker_processing.png"><img src="/imgs/post-imgs/amazon_sagemaker_processing.png"></a>
	<figcaption>Amazon SageMaker Processing.</figcaption>
</figure>

위와 같이 API로 분석을 요청하면 SageMaker Clarify는 SageMaker Processing Job을 실행하여 분석을 진행한다. 이 construct는 규모가 큰 학습 전, 학습 후, 또는 모델을 분석하기 위한 데이터 처리 과제들을 수행한다. 데이터는 S3 bucket에서 수집하고 processing cluster에서 처리되는데, 이때 클러스터는 다양한 container를 포함한다. Sklearn이나 Python은 기본적으로 설치되어있고, 이외에도 새로운 container를 추가할 수 있다. Processing cluster가 데이터 처리를 완료하면 지정된 S3 경로로 결과 데이터를 전송한다. 


## 2. Feature Importance with SHAP

[FI(Feature Importance)](https://shap.readthedocs.io/en/latest/)란 학습 데이터의 각각의 피쳐를 importance 점수를 매기는 분석이다. 다른 피쳐 또는 타겟에 대해 각 피쳐가 어떤 영향을 미치는 지를 알아본다.

SHAP(SHapley Additive exPlanations)는 open source framework로 게임 이론을 활용한 Shapley values에 기반한 분석 방법이다. 각각의 피쳐가 게임의 player라고 가정하고 모델의 예측은 payout으로 간주한다. SHAP 프레임워크는 지역적 설명과 전역 설명 분석 방식을 모두 제공한다. 지역적 설명(local explanation)은 최종 모델에 각각의 피쳐가 기여하는 정도에 초점을 맞추고, 전역 설명(global explanation)은 보다 광범위하게 전체 데이터가 모델에 미치는 영향에 초점을 맞춘다. 모든 결과와 피쳐 값 조합을 탐색한다는 점에서 연산 시간이 오래 걸리는 단점이 있지만, 덕분에 일관적인 결과와 지역적 정확성(local accuracy)을 보장하는 특성이 있다.

### 2.1. Amazon SageMaker Data Wrangler로 FI 측정하기

